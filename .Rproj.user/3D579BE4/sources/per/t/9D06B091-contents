#' Check directory
#' 
#' Create dir if does not exists.
#' Add slash to the end of the directory name.
#' 
#' @param dir directory name
#' @export
check_dir<- function(dir){
  bool <- endsWith(dir, "/")
  if(!bool){
    dir <- paste(dir, '/', sep="")
  }
  if(!dir.exists(dir)){
    dir.create(outdir, recursive =TRUE)
  }
  return(dir)
}

#' Get read, variant, sample and replicate counts
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param stat_df data frame with the following variables: parameters, asv_count, read_count, read_count, sample_count, sample_replicate_count
#' @param stage name of the filtering step; it is used for labeling the line in the stat_df
#' @param params parameter value (or their concatenation if more than one) used for the filtering step
#' @export
get_stat <- function(read_count_df, stat_df, stage, params=NA){
  #define a temporary data frame
  df <- data.frame(parameters=character(),
                   asv_count=integer(),
                   read_count=integer(),
                   sample_count=integer(),
                   sample_replicate_count=integer())
  #' get 4 different counts and place then into a data fram
  sample_repl <- paste(read_count_df$sample, read_count_df$replicate, sep="-")
  df[1,"parameters"] <-params
  df[1,"asv_count"] <-length(unique(read_count_df$asv))
  df[1,"read_count"] <-  sum(read_count_df$read_count)
  df[1,"sample_count"] <-length(unique(read_count_df$sample))
  df[1,"sample_replicate_count"] <-length(unique(sample_repl))
  #' add rowname
  rownames(df) <- c(stage)
  #' add new data to stat_df
  rbind(stat_df, df)
}

#' Read a fasta file, demultiplex reads and count them
#' 
#' Read only sequences from input fasta file.
#' Transform all nt to upper case.
#' Demultiplex reads to ASVs.
#' Count the number of reads of each ASVs.
#' Return a tibble with asv and nb_reads.
#' 
#' @param file tsv file with columns: plate	marker	sample	replicate	file
#' @export
read_fasta_count_reads <- function (file) {
  fas <- read.fasta(file, seqonly = T)
  # transform lust to matrix (1 column)
  fas <-as.matrix(fas)
  # all nt to upper case letters
  fas <-toupper(fas)
  # transform matrix to df. If I want to do it directly from list, it will put each sequence to one separate column
  fas <- as.data.frame(fas)
  colnames(fas) <- c("asv")
  
  # make unique list of sequences and count them
  read_count_df <- fas %>%
    group_by(asv) %>%
    summarize(read_count=length(asv))
  return(read_count_df)
}

#' Read all fasta files in fileinfo file to a data frame
#' 
#' Read all fasta file in fileinfo file (plate	marker	sample	replicate	filename).
#' Demultiplex reads to ASVs.
#' Count the number of reads of each ASVs in each sample-replicate.
#' Returns a df ("asv", "plate", "marker", "sample", "replicate", "read_count").
#' 
#' @param file tsv file with columns: plate	marker	sample	replicate	file
#' @param dir name of the directory with fasta file 
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
read_fastas_from_fileinfo <- function (file, dir, write_csv=F, outdir=NA) {
  # read all fasta files in fileinfo to a read_count_df
  # read fileinfo to df
  fileinfo_df <- read.csv(file, header=T, sep="\t")
  dir <- check_dir(dir)
  # define empty read_count_df to pool the results of variables
  read_count_df <- data.frame(asv=character(),
                              read_count=integer(),
                              plate=character(),
                              marker=character(),
                              sample=character(),
                              replicate=character())
  # read all fasta files in fileinfo and count the reads
  for(i in 1:length(fileinfo_df$filename)){
    fas <- paste(dir, fileinfo_df$filename[i], sep = "")
    print(fas)
    if(file.size(fas) < 50){ #' an empty file gzipped has 42 size => skip these files, An unzipped fasta with 80 nt is bigger than 50
      next
    }

    read_count_df_tmp <- read_fasta_count_reads(fas)
    read_count_df_tmp$plate <- fileinfo_df[i,"plate"]
    read_count_df_tmp$marker <- fileinfo_df[i,"marker"]
    read_count_df_tmp$sample <- fileinfo_df[i,"sample"]
    read_count_df_tmp$replicate <- fileinfo_df[i,"replicate"]
    read_count_df <- rbind(read_count_df, read_count_df_tmp)
  }
  rm(read_count_df_tmp)
  # reorder columns
  read_count_df <- read_count_df[, c("asv", "plate", "marker", "sample", "replicate", "read_count")]
  
  if(write_csv){
     write.csv(read_count_df, file = paste(outdir, "Input.csv", sep=""))
  }
  return(read_count_df)
}

#' LFN_global_read_count
#' 
#' Eliminate ASVs with less than cutoff reads in the dataset
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff minimum number of reads for an ASV; default=10
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
LFN_global_read_count <- function (read_count_df, cutoff=10, write_csv=F, outdir=NA) {
  df <- read_count_df %>%
    group_by(asv) %>%
    summarize(read_count=sum(read_count)) %>%
    filter(read_count > cutoff)
  read_count_df <- filter(read_count_df, (asv %in% df$asv))
  
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "LFN_global_read_count.csv", sep=""))
  }
  return(read_count_df)
}

#' LFN_read_count
#' 
#' Eliminate occurrences with less than cutoff reads
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff minimum number of reads for an occurrence; default=10; default=10
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
LFN_read_count <- function (read_count_df, cutoff=10, write_csv=F, outdir=NA) {
  read_count_df <- filter(read_count_df,  (read_count >= cutoff))
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "LFN_read_count.csv", sep=""))
  }
  return(read_count_df)
}

#' LFN_sample_replicate
#' 
#' Eliminate occurrences where the readcount/sum(reacount of the sample-replicate) is less than cutoff
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff minimum proportion for an occurrence within a sample-replicate; default=0.001
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
LFN_sample_replicate <- function (read_count_df, cutoff=0.001, write_csv=F, outdir=NA) {
  
  #Make wide format from de df
  wide_read_count_df <- as.data.frame(pivot_wider(read_count_df, names_from = c(plate, marker, sample, replicate), values_from = read_count, values_fill=0, names_sep = ";"))
  # when using sweep non-numeric values make a problem => keep asv for later
  asv_list <- wide_read_count_df$asv
  wide_read_count_df$asv <- NULL
  # divide all values by the sum of the columns
  wide_read_count_df_prop <- sweep(wide_read_count_df, MARGIN = 2, STATS = colSums(wide_read_count_df), FUN = "/")
  # 0 to values under cutoff
  wide_read_count_df_prop[wide_read_count_df_prop < cutoff] <- 0
  # NA to values of the df with counts, where the prop has been put to zero
  wide_read_count_df[wide_read_count_df_prop == 0] <- NA
  # add asv column
  wide_read_count_df$asv <- asv_list
  # re-transform to long format; avoid lines with O values
  read_count_df_lnf_sample_replicate <- pivot_longer(wide_read_count_df, cols = -asv, names_to = c("plate", "marker", "sample", "replicate"), values_to = "read_count", names_sep = ";", values_drop_na = TRUE)
  
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "LFN_sample_replicate.csv", sep=""))
  }
  return(read_count_df_lnf_sample_replicate)
}
#' LFN_variant_all
#' 
#' Eliminate occurrences where the read_count/sum(read_count of the asv) is less than cutoff 
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff minimum proportion for an occurrence within an asv; default=0.001
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
LFN_variant_all <- function (read_count_df, cutoff=0.001, write_csv=F, outdir=NA) {
  
  #Make wide format from de df
  wide_read_count_df <- as.data.frame(pivot_wider(read_count_df, names_from = c(plate, marker, sample, replicate), values_from = read_count, values_fill=0, names_sep = ";"))
  # when using sweep non-numeric values make a problem => keep asv for later
  asv_list <- wide_read_count_df$asv
  wide_read_count_df$asv <- NULL
  # divide all values by the sum of the columns
  wide_read_count_df_prop <- sweep(wide_read_count_df, MARGIN = 1, STATS = rowSums(wide_read_count_df), FUN = "/")
  # 0 to values under cutoff
  wide_read_count_df_prop[wide_read_count_df_prop < cutoff] <- 0
  # NA to values of the df with counts, where the prop has been put to zero
  wide_read_count_df[wide_read_count_df_prop == 0] <- NA
  # add asv column
  wide_read_count_df$asv <- asv_list
  # retransform to long format; avoid lines with 0 values
  read_count_df_lnf_sample_replicate <- pivot_longer(wide_read_count_df, cols = -asv, names_to = c("plate", "marker", "sample", "replicate"), values_to = "read_count", names_sep = ";", values_drop_na = TRUE)
  
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "LFN_variant_all.csv", sep=""))
  }
  return(read_count_df_lnf_sample_replicate)
}
#' LFN_variant_replicate
#' 
#' Eliminate occurrences where the read_count/sum(read_count of the asv within its replicate) is less than cutoff 
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff minimum proportion for an occurrence within a asv-replicate; default=0.001
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory 
#' @export
LFN_variant_replicate <- function (read_count_df, cutoff=0.001, write_csv=F, outdir=NA) {
  
  #get the list of replicates
  replicate_list <- unique(read_count_df$replicate)
  # defile an empty dataframe
  read_count_df_lnf_variant_replicate  <- data.frame(asv=character(),
                                                     read_count=integer(),
                                                     plate=character(),
                                                     marker=character(),
                                                     sample=character(),
                                                     replicate=character())
  # make one data frame for each replicate and filter them as in filter_lnf_variant
  for(i in replicate_list){
    replicate_df <- filter(read_count_df,  (replicate == i))
    replicate_df_filtered <- LFN_variant_all(replicate_df, cutoff, write_csv, outdir)
    read_count_df_lnf_variant_replicate <- rbind(read_count_df_lnf_variant_replicate, replicate_df_filtered)
  }
  
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "LFN_variant_replicate.csv", sep=""))
  }
  return(read_count_df_lnf_variant_replicate)
}

#' LFN_variant
#' 
#' If by_replicate=F: Eliminate occurrences where the read_count/sum(read_count of the asv) is less than cutoff 
#' If by_replicate=T: Eliminate occurrences where the read_count/sum(read_count of the asv with its replicate) is less than cutoff 
#' 
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff minimum proportion for an occurrence within an asv or an asv-replicate; default=0.001
#' @by_replicate T/F; default=FALSE
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
LFN_variant <- function (read_count_df, cutoff=0.001, by_replicate=FALSE, write_csv=F, outdir=NA) {
  if(by_replicate == T){
    read_count_df_lnf_variant <- LFN_variant_replicate(read_count_df, cutoff, write_csv, outdir)
  }
  else{
    read_count_df_lnf_variant <- LFN_variant_all(read_count_df, cutoff, write_csv, outdir)
  }
  return(read_count_df_lnf_variant)
}
#' pool_2df
#' 
#' pool 2 count_read_df data frames, and keep only occurrences present in all filters
#' 
#' @param df1 data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param df2 data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @export
pool_2df <- function (df1, df2) {
  merged_df <- merge(df1, df2, by = c("asv", "plate", "marker" ,"sample", "replicate"),  all = FALSE)
  test <- merged_df$read_count.x == merged_df$read_count.y
  if(FALSE %in% test){
    print("ERROR: Not all read counts are identical in data.frame comparison")
  }else{
    merged_df$read_count <- merged_df$read_count.x
    merged_df$read_count.y <- NULL    
    merged_df$read_count.x <- NULL    
  }
  return(merged_df)
}

#' pool_LFN
#' 
#' pool all count_read_df data frames, and keep only occurrences present in all filters
#' 
#' @param ... a list of data frames
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
#' 
pool_LFN <- function (... , write_csv=F, outdir=NA) {
  df_list <- list(...)
  merged <-  df_list[[1]]
  for(i in 2:length(df_list)){
    merged <- pool_2df(merged, df_list[[i]])
  }
  
  if(write_csv){
    write.csv(merged, file = paste(outdir, "LFN_pooled.csv", sep=""))
  }
  return(merged)
}

#' FilterMinReplicateNumber
#' 
#' Filter out all occurrences where the asv in not present in cutoff replicates
#'  
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param cutoff Minimum number of replicates; default=2
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
#'
FilterMinReplicateNumber <- function(read_count_df, cutoff=2, write_csv=F, outdir=NA){
  # add a temporary column with asv and sample concatenated
  read_count_df$tmp <- paste(read_count_df$asv,  read_count_df$sample, sep="-")
  # make a df_tmp containing the number of replicates for each asv-sample combination
  df_tmp <- read_count_df  %>%
    group_by(tmp) %>%
    summarize(repl_number=length(tmp))  %>%
    filter(repl_number >= cutoff)
  # keep only asv-sample if present at least in min_replicate_number replicates
  read_count_df <- filter(read_count_df, (read_count_df$tmp %in% df_tmp$tmp))
  read_count_df$tmp <- NULL
  
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "FilterMinReplicateNumber.csv", sep=""))
  }
  return(read_count_df)
}

#' FilterIndel
#' 
#' Filter out all ASVs, if the modulo 3 of their length is not the same as that of the majority of the ASVs
#'  
#' @param read_count_df data frame with the following variables: asv, plate, marker, sample, replicate, read_count
#' @param write_csv T/F; write read_counts to csv file; default=FALSE
#' @param outdir name of the output directory
#' @export
FilterIndel <- function(read_count_df, write_csv=F, outdir){
  # add a column with the modulo 3 of the length of the asvs
  read_count_df$mod3 <- nchar(read_count_df$asv) %% 3
  # make a tibble with modulo3 of the length of the ASVs and their count 
  # ASVs are counted as many times as they occur, so the most frequent ASV have higher weight
  # read_counts are not taken into account
  tmp <- read_count_df %>%
    group_by(mod3) %>%
    summarize(length_modulo=length(mod3)) %>%
    arrange(desc(length_modulo))
  # get the modulo 3 the most frequent
  my_modulo3 <- as.integer(tmp[1,"mod3"])
  # select only the lines with asv length compatible with the most frequent modulo3
  read_count_df <- read_count_df %>%
    filter(mod3 == my_modulo3)
  
  # delete the temporary colum
  read_count_df$mod3 <- NULL
  
  if(write_csv){
    write.csv(read_count_df, file = paste(outdir, "FilerIndel.csv", sep=""))
  }
  return(read_count_df)
}
