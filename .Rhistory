library("devtools")
library("roxygen2")
library("seqinr") # splitseq for FilterCodonStop
library("dplyr")
library("tidyr") # gather for read_asv_table; pivot_wider in WriteAsVtable and stat_sample !!sym
#library("utils") # to handle zipped files
library("ggplot2")
computer <- "Windows" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
swarm_path <- ""
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastq_dir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
#      fastq_dir <- "/home/meglecz/vtamR_large_files/fastq/"
#      fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#     outdir <- "/home/meglecz/vtamR_large_files/out/"
#     mock_composition <- "/home/meglecz/vtamR_large_files/user_input/mock_composition_mfzr.csv"
#     asv_list <- "/home/meglecz/vtamR_large_files/user_input/asv_list.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
swarm_path <- ""
db_path= "~/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
#    fastq_dir <- "vtamR_test/data/"
#     fastqinfo <- "vtamR_test/data/fastqinfo_mfzr.csv"
#     outdir <- "vtamR_test/out_mfzr/"
#     mock_composition <- "vtamR_test/data/mock_composition_mfzr.csv"
#     asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
fastq_dir <- "~/vtamR_large_data"
fastqinfo <- "~/vtamR_large_data/metadata/fastqinfo_Sea18_IIICBR_vtamR.csv"
outdir <- "/home/emese/vtamR_large_data/out/"
mock_composition <- "~/vtamR_large_data/metadata/mock_composition_Sea18_IIICBR_vtamR.csv"
asv_list <- "~/vtamR_large_data/metadata/asv_list.csv"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/swarm-3.1.4-win-x86_64/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastq_dir <- "C:/Users/emese/vtamR_private/fastq/"
fastq_dir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr.csv"
outdir <- "vtamR_test/out_mfzr/"
mock_composition <- "vtamR_test/data/mock_composition_mfzr.csv"
asv_list <- "vtamR_test/data/asv_list.csv"
num_threads=4
compress = F
}
sep=","
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Run swarm
###
read_count_df <- read.csv(paste(outdir, "1_before_filter.csv", sep=""), sep=sep)
outdir
swarm_d <- 1
fastidious <- TRUE
by_sample <- FALSE
outfile <- paste(outdir, "2_Swarm_by_sample.csv", sep="")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, sep=sep, by_sample=by_sample)
###
# Run swarm
###
read_count_df <- read.csv(paste(outdir, "1_before_filter.csv", sep=""), sep=sep)
swarm_d <- 1
fastidious <- TRUE
by_sample <- FALSE
quiet <- F
outfile <- paste(outdir, "2_Swarm_by_sample.csv", sep="")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, sep=sep, by_sample=by_sample, quiet=quiet)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Run swarm
###
read_count_df <- read.csv(paste(outdir, "1_before_filter.csv", sep=""), sep=sep)
swarm_d <- 1
fastidious <- TRUE
by_sample <- FALSE
quiet <- F
outfile <- paste(outdir, "2_Swarm_by_sample.csv", sep="")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, sep=sep, by_sample=by_sample, quiet=quiet)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Run swarm
###
read_count_df <- read.csv(paste(outdir, "1_before_filter.csv", sep=""), sep=sep)
swarm_d <- 1
fastidious <- TRUE
by_sample <- FALSE
quiet <- F
outfile <- paste(outdir, "2_Swarm_by_sample.csv", sep="")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, sep=sep, by_sample=by_sample, quiet=quiet)
View(read_count_df)
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
###
# Run swarm
###
read_count_df <- read.csv(paste(outdir, "1_before_filter.csv", sep=""), sep=sep)
# make stat counts
stat_df <- get_stat(read_count_df, stat_df, stage="Input", params=NA)
swarm_d <- 1
fastidious <- TRUE
by_sample <- FALSE
quiet <- F
outfile <- paste(outdir, "2_Swarm_by_sample.csv", sep="")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, sep=sep, by_sample=by_sample, quiet=quiet)
params <- paste(swarm_d, fastidious, by_sample, sep=";")
stat_df <- get_stat(read_count_df, stat_df, stage="swarm_by_sample", params=params)
View(stat_df)
###
### LFN_global_read_count
###
# Eliminate variants with less than global_read_count_cutoff reads in the dataset
global_read_count_cutoff = 2
outfile <- paste(outdir, "3_LFN_global_read_count.csv", sep="")
read_count_df <- LFN_global_read_count(read_count_df, cutoff=global_read_count_cutoff, outfile=outfile)
stat_df <- get_stat(read_count_df, stat_df, stage="LFN_global_read_count", params=global_read_count_cutoff)
###
### LFN_filters
###
# LFN_read_count
lfn_read_count_cutoff <- 10
outfile <- paste(outdir, "4_LFN_read_count.csv", sep="")
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df_lfn_read_count, stat_df, stage="LFN_read_count", params=lfn_read_count_cutoff)
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
outfile <- paste(outdir, "5_LFN_sample_replicate.csv", sep="")
read_count_df_lnf_sample_replicate <- LFN_sample_replicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df_lnf_sample_replicate, stat_df, stage="LFN_sample_replicate", params=lfn_sample_replicate_cutoff)
# LFN_variant (by line)
lnf_variant_cutoff = 0.001
by_replicate = TRUE
outfile <- paste(outdir, "6_LFN_variant_replicate.csv", sep="")
min_read_count_prop = 0.7
read_count_df_lnf_variant <- LFN_variant(read_count_df, cutoff=lnf_variant_cutoff, by_replicate, outfile=outfile, sep=sep, min_read_count_prop=min_read_count_prop)
param_values <- paste(lnf_variant_cutoff, by_replicate, sep=";")
stat_df <- get_stat(read_count_df_lnf_variant, stat_df, stage="LFN_variant", params=param_values)
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
outfile <- paste(outdir, "7_pool_LFN.csv", sep="")
read_count_df <- pool_LFN(read_count_df_lfn_read_count, read_count_df_lnf_variant, read_count_df_lnf_sample_replicate, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterLFN")
# delete temporary data frames
read_count_df_lfn_read_count <- NULL
read_count_df_lnf_variant <- NULL
read_count_df_lnf_sample_replicate <- NULL
###
### keep repeatable occurrences
###
min_replicate_number <- 2
outfile <- paste(outdir, "8_FilterMinReplicateNumber.csv", sep="")
read_count_df <- FilterMinReplicateNumber(read_count_df, min_replicate_number, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterMinReplicateNumber", params=min_replicate_number)
###
### FilerIndel
###
outfile <- paste(outdir, "9_FilterIndel.csv", sep="")
read_count_df <- FilterIndel(read_count_df, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterIndel")
###
### FilterCodonStop
###
outfile <- paste(outdir, "10_FilterCodonStop.csv", sep="")
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, outfile=outfile, genetic_code=genetic_code, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilerCodonStop", params=genetic_code)
###
### FilerPCRerror
###
pcr_error_var_prop <- 0.1
max_mismatch <- 2
by_sample <- T
sample_prop <- 0.8
outfile <- paste(outdir, "11_FilterPCRerror.csv", sep="")
read_count_df <- FilterPCRerror(read_count_df, outfile=outfile, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
params <- paste(pcr_error_var_prop, max_mismatch, by_sample, sample_prop, sep=";")
stat_df <- get_stat(read_count_df, stat_df, stage="FilerPCRerror", params=params)
###
### FilterChimera
###
abskew=2
by_sample = T
sample_prop = 0.8
outfile <- paste(outdir, "12_FilterChimera.csv", sep="")
read_count_df <- FilterChimera(read_count_df, outfile=outfile, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
params <- paste(abskew, by_sample, sample_prop, sep=";")
stat_df <- get_stat(read_count_df, stat_df, stage="FilterChimera", params=params)
###
# Avoid rerunning the longest step
###
read_count_df <- read.csv(paste(outdir, "12_FilterChimera.csv", sep =""), sep=sep)
sorted_dir <- paste(outdir, "sorted/", sep="")
sorted_dir <- paste(outdir, "sorted/", sep="")
sortedinfo <- paste(sorted_dir, "sortedinfo.csv", sep="")
stat_df <- get_stat(read_count_df, stat_df, stage="FilterChimera", params=params)
###
### FilterRenkonen
###
# Renkonen index:
# PS = summ(min(p1i, p2i))
# p1i = number of reads for variant i in replicate 1 / number of reads in replicate 1
renkonen_distance_quantile = 0.9
outfile <- paste(outdir, "13_FilterRenkonen.csv", sep="")
read_count_df <- FilterRenkonen(read_count_df, outfile=outfile, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilerRenkonen", params=renkonen_distance_quantile)
###
### PoolReplicates
###
digits = 0
outfile <- paste(outdir, "14_PoolReplicates.csv", sep="")
read_count_samples_df <- PoolReplicates(read_count_df, digits=digits, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_samples_df, stat_df, stage="PoolReplicates")
View(read_count_samples_df)
###
### TaxAssign
###
outfile <- paste(outdir, "TaxAssign.csv", sep="")
asv_tax <- TaxAssign(asv=read_count_samples_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outfile=outfile, num_threads=num_threads)
asv_tax <- TaxAssign(asv=read_count_samples_df, ltg_params=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outfile=outfile, num_threads=num_threads)
ltg_params_df
is.character(ltg_params_df)
is.character("")
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
### TaxAssign
###
outfile <- paste(outdir, "TaxAssign.csv", sep="")
asv_tax <- TaxAssign(asv=read_count_samples_df, ltg_params=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outfile=outfile, num_threads=num_threads)
ltg_params = "vtamR_test/data/ltg_params.csv"
###
### TaxAssign
###
outfile <- paste(outdir, "TaxAssign.csv", sep="")
asv_tax <- TaxAssign(asv=read_count_samples_df, ltg_params=ltg_params, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outfile=outfile, num_threads=num_threads)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=F)
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=F)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=F)
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=T)
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=T)
# load local packages
load_all(".")
# load local packages
load_all(".")
roxygenise()
usethis::use_roxygen_md()
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=F)
test_Filters(test_dir="vtamR_test/", swarm_path=swarm_path, vsearch_path=vsearch_path, sep=sep, delete_tmp=F)
test_MakeKnownOccurrences(test_dir="vtamR_test/", sep=sep, delete_tmp=F)
test_Optimize(test_dir="vtamR_test/", vsearch_path=vsearch_path, delete_tmp=F)
test_TaxAssign(test_dir="vtamR_test/", sep=sep, blast_path=blast_path, num_threads=num_threads, delete_tmp=F)
test_TaxAssign(test_dir="vtamR_test/", sep=sep, blast_path=blast_path, num_threads=num_threads)
###
# Test major functions
###
test_Merge_and_SortReads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, delete_tmp=T)
test_Filters(test_dir="vtamR_test/", swarm_path=swarm_path, vsearch_path=vsearch_path, sep=sep, delete_tmp=T)
test_MakeKnownOccurrences(test_dir="vtamR_test/", sep=sep, delete_tmp=T)
test_Optimize(test_dir="vtamR_test/", vsearch_path=vsearch_path, delete_tmp=T)
test_TaxAssign(test_dir="vtamR_test/", sep=sep, blast_path=blast_path, num_threads=num_threads)
