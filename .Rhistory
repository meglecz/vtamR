max_mismatch <- 2
by_sample <- T
sample_prop <- 0.3
FilterPCRerror_df2 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df2 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr2_03_out.csv", sep=""), sep=sep)
comp_FilterPCRerror_2 <- compare_df(FilterPCRerror_df2, FilterPCRerror_exp_df2, step="FilterPCRerror")
### FilterChimera
test_input_file_cim <- paste(test_dir, "test/test_file2.csv", sep="")
input_df_chim <- read_asv_table(filename=test_input_file_cim, sep=sep)
abskew=10
by_sample = T
sample_prop = 0.3
FilterChimera_10_03_df <- FilterChimera(input_df_chim, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
FilterChimera_10_03_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_chimera_out_03_10.csv", sep=""), sep=sep)
comp_FilterChimera_10_03 <- compare_df(FilterChimera_10_03_df, FilterChimera_10_03_exp_df, step="FilterChimera")
abskew=10
by_sample = T
sample_prop = 0.6
FilterChimera_10_06_df <- FilterChimera(input_df_chim, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
FilterChimera_10_06_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_chimera_out_06_10.csv", sep=""), sep=sep)
comp_FilterChimera_10_06 <- compare_df(FilterChimera_10_06_df, FilterChimera_10_06_exp_df, step="FilterChimera")
### FilterRenkonen
renkonen_distance_quantile = 0.9
FilterRenkonen_df <- FilterRenkonen(input_df, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
FilterRenkonen_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_FilterRenkonen_09_out.csv", sep=""), sep=sep)
comp_FilterRenkonen <- compare_df(FilterRenkonen_df, FilterRenkonen_exp_df, step="FilerRenkonen")
renkonen_distance_quantile = 0.8
FilterRenkonen_df <- FilterRenkonen(input_df, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
FilterRenkonen_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_FilterRenkonen_08_out.csv", sep=""), sep=sep)
comp_FilterRenkonen <- compare_df(FilterRenkonen_df, FilterRenkonen_exp_df, step="FilerRenkonen")
### FilerIndel
FilterIndel_df <- FilterIndel(input_df, sep=sep)
FilterIndel_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_indel_out.csv", sep=""), sep=sep)
comp_FilterIndel <- compare_df(FilterIndel_df, FilterIndel_exp_df, step="FilterIndel")
### FilerCodonStop
genetic_code = 5
FilterCodonStop_df <- FilterCodonStop(input_df, genetic_code=genetic_code, sep=sep)
FilterCodonStop_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_stop_out.csv", sep=""), sep=sep)
comp_FilterCodonStop <- compare_df(FilterCodonStop_df, FilterCodonStop_exp_df, step="FilterCodonStop")
### PoolReplicates
digits = 0
PoolReplicates_df <- PoolReplicates(input_df, digits=digits, sep=sep)
PoolReplicates_exp_df <- read_asv_table_sample(filename=paste(test_dir, "test/test_file_pool_replicate_out.csv", sep=""), sep=sep)
PoolReplicates_exp_df <- PoolReplicates_exp_df %>% rename("asv_id"=seq_id)
comp_PoolReplicates <- compare_df_sample(PoolReplicates_df, PoolReplicates_exp_df, step="PoolReplicates")
#LFN_global_read_count
global_read_count_cutoff = 50
global_read_count_cutoff_df <- LFN_global_read_count(input_df, global_read_count_cutoff, sep=sep)
global_read_count_cutoff_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_global_read_count50_out.csv", sep=""), sep=sep)
comp_LFN_global_read_count <- compare_df(global_read_count_cutoff_df, global_read_count_cutoff_exp_df, step="LFN_global_read_count")
test_filters <- function(test_dir="~/vtamR/vtamR_test/", vsearch_path="", sep=","){
test_dir <- check_dir(test_dir)
outdir <- paste(test_dir, "out", sep="")
outdir <- check_dir(outdir)
test_input_file <- paste(test_dir, "test/test_file.csv", sep="")
### make input df
input_df <- read_asv_table(filename=test_input_file, sep=sep) %>%
rename("asv_id"=seq_id)
#LFN_global_read_count
global_read_count_cutoff = 50
global_read_count_cutoff_df <- LFN_global_read_count(input_df, global_read_count_cutoff, sep=sep)
global_read_count_cutoff_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_global_read_count50_out.csv", sep=""), sep=sep)
comp_LFN_global_read_count <- compare_df(global_read_count_cutoff_df, global_read_count_cutoff_exp_df, step="LFN_global_read_count")
input_df_tmp <- input_df %>%
select(-seq_id)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
lfn_read_count_df <- LFN_read_count(input_df_tmp, cutoff=lfn_read_count_cutoff, sep=sep)
lfn_read_count_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_min_read_count_out.csv", sep=""), sep=sep)
comp_LFN_read_count <- compare_df(lfn_read_count_df, lfn_read_count_exp_df, step="LFN_read_count")
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
lnf_sample_replicate_df <- LFN_sample_replicate(input_df_tmp, cutoff=lfn_sample_replicate_cutoff, sep=sep)
lnf_sample_replicate_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_sample_replicate_out.csv", sep=""), sep=sep)
comp_LFN_sample_replicate <- compare_df(lnf_sample_replicate_df, lnf_sample_replicate_exp_df, step="LFN_sample_replicate")
# LFN_variant_replicate (by line)
lnf_variant_cutoff = 0.002
by_replicate = TRUE
lnf_variant_replicate_df <- LFN_variant(input_df_tmp, cutoff=lnf_variant_cutoff, by_replicate=by_replicate, sep=sep)
lnf_variant_replicate_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_variant_replicate002_out.csv", sep=""), sep=sep)
comp_LFN_variant_replicate <- compare_df(lnf_variant_replicate_df, lnf_variant_replicate_exp_df, step="LFN_variant_replicate")
# LFN_variant (by line)
lnf_variant_cutoff = 0.002
by_replicate = FALSE
lnf_variant_df <- LFN_variant(input_df_tmp, cutoff=lnf_variant_cutoff, by_replicate=by_replicate, sep=sep)
lnf_variant_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_variant002_out.csv", sep=""), sep=sep)
comp_LFN_variant <- compare_df(lnf_variant_df, lnf_variant_exp_df, step="LFN_variant")
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
lfn_pool_df <- pool_LFN(lfn_read_count_df, lnf_sample_replicate_df, lnf_variant_df, sep=sep)
lnf_pool_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_pool_LFN_out.csv", sep=""), sep=sep)
comp_LFN_variant <- compare_df(lfn_pool_df, lnf_pool_exp_df, step="pool_LFN")
### keep repeatable occurrences
min_replicate_number <- 2
FilterMinReplicateNumber_df <- FilterMinReplicateNumber(input_df, min_replicate_number, sep=sep)
FilterMinReplicateNumber_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_repeat_out.csv", sep=""), sep=sep)
comp_FilterMinReplicateNumber <- compare_df(FilterMinReplicateNumber_df, FilterMinReplicateNumber_exp_df, step="FilterMinReplicateNumber")
### FilterPCRerror
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 0.3
FilterPCRerror_df1 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df1 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr1_03_out.csv", sep=""), sep=sep)
comp_FilterPCRerror1 <- compare_df(FilterPCRerror_df1, FilterPCRerror_exp_df1, step="FilterPCRerror")
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 0.6
FilterPCRerror_df1_6 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df1_6 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr1_06_out.csv", sep=""), sep=sep)
comp_FilterPCRerror1_6 <- compare_df(FilterPCRerror_df1_6, FilterPCRerror_exp_df1_6, step="FilterPCRerror")
pcr_error_var_prop <- 0.1
max_mismatch <- 2
by_sample <- T
sample_prop <- 0.3
FilterPCRerror_df2 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df2 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr2_03_out.csv", sep=""), sep=sep)
comp_FilterPCRerror_2 <- compare_df(FilterPCRerror_df2, FilterPCRerror_exp_df2, step="FilterPCRerror")
### FilterChimera
test_input_file_cim <- paste(test_dir, "test/test_file2.csv", sep="")
input_df_chim <- read_asv_table(filename=test_input_file_cim, sep=sep)
abskew=10
by_sample = T
sample_prop = 0.3
FilterChimera_10_03_df <- FilterChimera(input_df_chim, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
FilterChimera_10_03_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_chimera_out_03_10.csv", sep=""), sep=sep)
comp_FilterChimera_10_03 <- compare_df(FilterChimera_10_03_df, FilterChimera_10_03_exp_df, step="FilterChimera")
abskew=10
by_sample = T
sample_prop = 0.6
FilterChimera_10_06_df <- FilterChimera(input_df_chim, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
FilterChimera_10_06_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_chimera_out_06_10.csv", sep=""), sep=sep)
comp_FilterChimera_10_06 <- compare_df(FilterChimera_10_06_df, FilterChimera_10_06_exp_df, step="FilterChimera")
### FilterRenkonen
renkonen_distance_quantile = 0.9
FilterRenkonen_df <- FilterRenkonen(input_df, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
FilterRenkonen_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_FilterRenkonen_09_out.csv", sep=""), sep=sep)
comp_FilterRenkonen <- compare_df(FilterRenkonen_df, FilterRenkonen_exp_df, step="FilerRenkonen")
renkonen_distance_quantile = 0.8
FilterRenkonen_df <- FilterRenkonen(input_df, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
FilterRenkonen_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_FilterRenkonen_08_out.csv", sep=""), sep=sep)
comp_FilterRenkonen <- compare_df(FilterRenkonen_df, FilterRenkonen_exp_df, step="FilerRenkonen")
### FilerIndel
FilterIndel_df <- FilterIndel(input_df, sep=sep)
FilterIndel_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_indel_out.csv", sep=""), sep=sep)
comp_FilterIndel <- compare_df(FilterIndel_df, FilterIndel_exp_df, step="FilterIndel")
### FilerCodonStop
genetic_code = 5
FilterCodonStop_df <- FilterCodonStop(input_df, genetic_code=genetic_code, sep=sep)
FilterCodonStop_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_stop_out.csv", sep=""), sep=sep)
comp_FilterCodonStop <- compare_df(FilterCodonStop_df, FilterCodonStop_exp_df, step="FilterCodonStop")
### PoolReplicates
digits = 0
PoolReplicates_df <- PoolReplicates(input_df, digits=digits, sep=sep)
PoolReplicates_exp_df <- read_asv_table_sample(filename=paste(test_dir, "test/test_file_pool_replicate_out.csv", sep=""), sep=sep)
PoolReplicates_exp_df <- PoolReplicates_exp_df %>% rename("asv_id"=seq_id)
comp_PoolReplicates <- compare_df_sample(PoolReplicates_df, PoolReplicates_exp_df, step="PoolReplicates")
}
test_filters(test_dir="vtamR_test/", vsearch_path=vsearch_path, sep=sep)
test_filters <- function(test_dir="~/vtamR/vtamR_test/", vsearch_path="", sep=","){
test_dir <- check_dir(test_dir)
outdir <- paste(test_dir, "out", sep="")
outdir <- check_dir(outdir)
test_input_file <- paste(test_dir, "test/test_file.csv", sep="")
### make input df
input_df <- read_asv_table(filename=test_input_file, sep=sep) %>%
rename("asv_id"=seq_id)
#LFN_global_read_count
global_read_count_cutoff = 50
global_read_count_cutoff_df <- LFN_global_read_count(input_df, global_read_count_cutoff, sep=sep)
global_read_count_cutoff_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_global_read_count50_out.csv", sep=""), sep=sep)
comp_LFN_global_read_count <- compare_df(global_read_count_cutoff_df, global_read_count_cutoff_exp_df, step="LFN_global_read_count")
input_df_tmp <- input_df %>%
select(-asv_id)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
lfn_read_count_df <- LFN_read_count(input_df_tmp, cutoff=lfn_read_count_cutoff, sep=sep)
lfn_read_count_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_min_read_count_out.csv", sep=""), sep=sep)
comp_LFN_read_count <- compare_df(lfn_read_count_df, lfn_read_count_exp_df, step="LFN_read_count")
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
lnf_sample_replicate_df <- LFN_sample_replicate(input_df_tmp, cutoff=lfn_sample_replicate_cutoff, sep=sep)
lnf_sample_replicate_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_sample_replicate_out.csv", sep=""), sep=sep)
comp_LFN_sample_replicate <- compare_df(lnf_sample_replicate_df, lnf_sample_replicate_exp_df, step="LFN_sample_replicate")
# LFN_variant_replicate (by line)
lnf_variant_cutoff = 0.002
by_replicate = TRUE
lnf_variant_replicate_df <- LFN_variant(input_df_tmp, cutoff=lnf_variant_cutoff, by_replicate=by_replicate, sep=sep)
lnf_variant_replicate_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_variant_replicate002_out.csv", sep=""), sep=sep)
comp_LFN_variant_replicate <- compare_df(lnf_variant_replicate_df, lnf_variant_replicate_exp_df, step="LFN_variant_replicate")
# LFN_variant (by line)
lnf_variant_cutoff = 0.002
by_replicate = FALSE
lnf_variant_df <- LFN_variant(input_df_tmp, cutoff=lnf_variant_cutoff, by_replicate=by_replicate, sep=sep)
lnf_variant_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_variant002_out.csv", sep=""), sep=sep)
comp_LFN_variant <- compare_df(lnf_variant_df, lnf_variant_exp_df, step="LFN_variant")
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
lfn_pool_df <- pool_LFN(lfn_read_count_df, lnf_sample_replicate_df, lnf_variant_df, sep=sep)
lnf_pool_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_pool_LFN_out.csv", sep=""), sep=sep)
comp_LFN_variant <- compare_df(lfn_pool_df, lnf_pool_exp_df, step="pool_LFN")
### keep repeatable occurrences
min_replicate_number <- 2
FilterMinReplicateNumber_df <- FilterMinReplicateNumber(input_df, min_replicate_number, sep=sep)
FilterMinReplicateNumber_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_repeat_out.csv", sep=""), sep=sep)
comp_FilterMinReplicateNumber <- compare_df(FilterMinReplicateNumber_df, FilterMinReplicateNumber_exp_df, step="FilterMinReplicateNumber")
### FilterPCRerror
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 0.3
FilterPCRerror_df1 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df1 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr1_03_out.csv", sep=""), sep=sep)
comp_FilterPCRerror1 <- compare_df(FilterPCRerror_df1, FilterPCRerror_exp_df1, step="FilterPCRerror")
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 0.6
FilterPCRerror_df1_6 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df1_6 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr1_06_out.csv", sep=""), sep=sep)
comp_FilterPCRerror1_6 <- compare_df(FilterPCRerror_df1_6, FilterPCRerror_exp_df1_6, step="FilterPCRerror")
pcr_error_var_prop <- 0.1
max_mismatch <- 2
by_sample <- T
sample_prop <- 0.3
FilterPCRerror_df2 <- FilterPCRerror(input_df, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
FilterPCRerror_exp_df2 = read_asv_table(filename=paste(test_dir, "test/test_file_pcr2_03_out.csv", sep=""), sep=sep)
comp_FilterPCRerror_2 <- compare_df(FilterPCRerror_df2, FilterPCRerror_exp_df2, step="FilterPCRerror")
### FilterChimera
test_input_file_cim <- paste(test_dir, "test/test_file2.csv", sep="")
input_df_chim <- read_asv_table(filename=test_input_file_cim, sep=sep)
abskew=10
by_sample = T
sample_prop = 0.3
FilterChimera_10_03_df <- FilterChimera(input_df_chim, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
FilterChimera_10_03_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_chimera_out_03_10.csv", sep=""), sep=sep)
comp_FilterChimera_10_03 <- compare_df(FilterChimera_10_03_df, FilterChimera_10_03_exp_df, step="FilterChimera")
abskew=10
by_sample = T
sample_prop = 0.6
FilterChimera_10_06_df <- FilterChimera(input_df_chim, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
FilterChimera_10_06_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_chimera_out_06_10.csv", sep=""), sep=sep)
comp_FilterChimera_10_06 <- compare_df(FilterChimera_10_06_df, FilterChimera_10_06_exp_df, step="FilterChimera")
### FilterRenkonen
renkonen_distance_quantile = 0.9
FilterRenkonen_df <- FilterRenkonen(input_df, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
FilterRenkonen_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_FilterRenkonen_09_out.csv", sep=""), sep=sep)
comp_FilterRenkonen <- compare_df(FilterRenkonen_df, FilterRenkonen_exp_df, step="FilerRenkonen")
renkonen_distance_quantile = 0.8
FilterRenkonen_df <- FilterRenkonen(input_df, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
FilterRenkonen_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_FilterRenkonen_08_out.csv", sep=""), sep=sep)
comp_FilterRenkonen <- compare_df(FilterRenkonen_df, FilterRenkonen_exp_df, step="FilerRenkonen")
### FilerIndel
FilterIndel_df <- FilterIndel(input_df, sep=sep)
FilterIndel_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_indel_out.csv", sep=""), sep=sep)
comp_FilterIndel <- compare_df(FilterIndel_df, FilterIndel_exp_df, step="FilterIndel")
### FilerCodonStop
genetic_code = 5
FilterCodonStop_df <- FilterCodonStop(input_df, genetic_code=genetic_code, sep=sep)
FilterCodonStop_exp_df = read_asv_table(filename=paste(test_dir, "test/test_file_stop_out.csv", sep=""), sep=sep)
comp_FilterCodonStop <- compare_df(FilterCodonStop_df, FilterCodonStop_exp_df, step="FilterCodonStop")
### PoolReplicates
digits = 0
PoolReplicates_df <- PoolReplicates(input_df, digits=digits, sep=sep)
PoolReplicates_exp_df <- read_asv_table_sample(filename=paste(test_dir, "test/test_file_pool_replicate_out.csv", sep=""), sep=sep)
PoolReplicates_exp_df <- PoolReplicates_exp_df %>% rename("asv_id"=seq_id)
comp_PoolReplicates <- compare_df_sample(PoolReplicates_df, PoolReplicates_exp_df, step="PoolReplicates")
}
test_filters(test_dir="vtamR_test/", vsearch_path=vsearch_path, sep=sep)
computer <- "Bombyx" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
swarm_path <- ""
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
#fastqdir <- "/home/meglecz/vtamR_large_files/fastq/"
#fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#outdir <- "/home/meglecz/vtamR_large_files/out/"
#mock_composition <- "local/user_input/mock_composition_mfzr_prerun.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
swarm_path <- ""
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "local/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/swarm-3.1.4-win-x86_64/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr_gz.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr_eu.csv"
num_threads=4
compress = F
}
sep=","
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files
test_merge_and_sortreads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
test_filters(test_dir="vtamR_test/", vsearch_path=vsearch_path, sep=sep)
# create the output directory and check the the slash at the end
outdir <- check_dir(dir=outdir)
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
###
### Merge
###
fastq_ascii <- 33
fastq_maxdiffs <- 10
fastq_maxee <- 1
fastq_minlen <- 50
fastq_maxlen <- 500
fastq_minmergelen <- 50
fastq_maxmergelen <-500
fastq_maxns <- 0
fastq_truncqual <- 10
fastq_minovlen <- 50
fastq_allowmergestagger <- F
merged_dir <- paste(outdir, "merged/", sep="")
compress = T
# read fastqinfo
fastqinfo_df <- read.csv(fastqinfo, header=T, sep=sep)
fastainfo_df <- Merge(fastqinfo_df=fastqinfo_df, fastqdir=fastqdir, vsearch_path=vsearch_path, outdir=merged_dir, fastq_ascii=fastq_ascii, fastq_maxdiffs=fastq_maxdiffs, fastq_maxee=fastq_maxee, fastq_minlen=fastq_minlen, fastq_maxlen=fastq_maxlen, fastq_minmergelen=fastq_minmergelen, fastq_maxmergelen=fastq_maxmergelen, fastq_maxns=fastq_maxns, fastq_truncqual=fastq_truncqual, fastq_minovlen=fastq_minovlen, fastq_allowmergestagger=fastq_allowmergestagger, sep=sep, compress=compress)
###
### RandomSeq
###
randomseq_dir = paste(outdir, "random_seq/", sep="")
#fastainfo <- paste(merged_dir, "fastainfo_gz.csv", sep="")
#fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
compress = T
RandomSeq(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, vsearch_path=vsearch_path, n=10000, randseed=0, compress=compress)
###
### SortReads
###
sorted_dir <- paste(outdir, "sorted/", sep="")
check_reverse <- T
tag_to_end <- F
primer_to_end <-F
cutadapt_error_rate <- 0.1 # -e in cutadapt
cutadapt_minimum_length <- 50 # -m in cutadapt
cutadapt_maximum_length <- 500 # -M in cutadapt
compress <- F
sortedinfo_df <- SortReads(fastainfo_df=fastainfo_df, fastadir=randomseq_dir, outdir=sorted_dir, cutadapt_path=cutadapt_path, vsearch_path=vsearch_path, check_reverse=check_reverse, tag_to_end=tag_to_end, primer_to_end=primer_to_end, cutadapt_error_rate=cutadapt_error_rate, cutadapt_minimum_length=cutadapt_minimum_length, cutadapt_maximum_length=cutadapt_maximum_length, sep=sep, compress=compress)
###
### Read input fasta files, dereplicate reads to ASV, and count the number of reads of each ASV in each sample-replicate, add a unique id for ASVs, can take into account ASVs from earlier analyses
###
outfile <- paste(outdir, "1_before_filter.csv", sep="")
sortedinfo_df <- read.csv(paste(sorted_dir, "sortedinfo.csv", sep =""), sep=sep)
updated_asv_list <- sub("\\.", "_updated_2024_02_15.", asv_list) # add date to the name of the input asv_list to get a file name for the updated_file
read_count_df <- read_fastas_from_fileinfo(sortedinfo_df, dir=sorted_dir, outfile=outfile, sep=sep, asv_list=asv_list, updated_asv_list=updated_asv_list)
read_count_df_backup <- read_count_df
read_count_df <- read_count_df_backup
# make stat counts
stat_df <- get_stat(read_count_df, stat_df, stage="Input", params=NA)
###
# Run swarm
###
swarm_d <- 1
fastidious <- TRUE
by_sample <- TRUE
outfile <- paste(outdir, "2_swarm.csv", sep="")
read_count_df <- swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, write_csv=T, sep=sep, by_sample=by_sample)
params <- paste(swarm_d, fastidious, by_sample, sep=";")
stat_df <- get_stat(read_count_df, stat_df, stage="swarm", params=params)
###
### LFN_global_read_count
###
# Eliminate variants with less than global_read_count_cutoff reads in the dataset
global_read_count_cutoff = 2
outfile <- paste(outdir, "3_LFN_global_read_count.csv", sep="")
read_count_df <- LFN_global_read_count(read_count_df, global_read_count_cutoff, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="LFN_global_read_count", params=global_read_count_cutoff)
###
### LFN_filters
###
# LFN_read_count
lfn_read_count_cutoff <- 10
outfile <- paste(outdir, "4_LFN_read_count.csv", sep="")
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df_lfn_read_count, stat_df, stage="LFN_read_count", params=lfn_read_count_cutoff)
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
outfile <- paste(outdir, "5_LFN_sample_replicate.csv", sep="")
read_count_df_lnf_sample_replicate <- LFN_sample_replicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df_lnf_sample_replicate, stat_df, stage="LFN_sample_replicate", params=lfn_sample_replicate_cutoff)
# LFN_sample_variant (by line)
lnf_variant_cutoff = 0.001
by_replicate = TRUE
outfile <- paste(outdir, "6_LFN_variant_replicate.csv", sep="")
read_count_df_lnf_variant <- LFN_variant(read_count_df, cutoff=lnf_variant_cutoff, by_replicate, outfile=outfile, sep=sep)
param_values <- paste(lnf_variant_cutoff, by_replicate, sep=";")
stat_df <- get_stat(read_count_df_lnf_variant, stat_df, stage="LFN_variant", params=param_values)
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
outfile <- paste(outdir, "7_pool_LFN.csv", sep="")
read_count_df <- pool_LFN(read_count_df_lfn_read_count, read_count_df_lnf_variant, read_count_df_lnf_sample_replicate, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterLFN")
# delete temporary data frames
read_count_df_lfn_read_count <- NULL
read_count_df_lnf_variant <- NULL
read_count_df_lnf_sample_replicate <- NULL
###
### keep repeatable occurrences
###
min_replicate_number <- 2
outfile <- paste(outdir, "8_FilterMinReplicateNumber.csv", sep="")
read_count_df <- FilterMinReplicateNumber(read_count_df, min_replicate_number, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterMinReplicateNumber", params=min_replicate_number)
###
### FilerIndel
###
outfile <- paste(outdir, "9_FilterIndel.csv", sep="")
read_count_df <- FilterIndel(read_count_df, outfile=outfile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterIndel")
###
### FilerCodonStop
###
outfile <- paste(outdir, "10_FilterCodonStop.csv", sep="")
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, outfile=outfile, genetic_code=genetic_code, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilerCodonStop", params=genetic_code)
###
### FilerPCRerror
###
pcr_error_var_prop <- 0.1
max_mismatch <- 2
by_sample <- T
sample_prop <- 0.8
outfile <- paste(outdir, "11_FilterPCRerror.csv", sep="")
read_count_df <- FilterPCRerror(read_count_df, outfile=outfile, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
params <- paste(pcr_error_var_prop, max_mismatch, by_sample, sample_prop, sep=";")
stat_df <- get_stat(read_count_df, stat_df, stage="FilerPCRerror", params=params)
###
### FilterChimera
###
abskew=2
by_sample = T
sample_prop = 0.8
outfile <- paste(outdir, "12_FilterChimera.csv", sep="")
read_count_df <- FilterChimera(read_count_df, outfile=outfile, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
params <- paste(abskew, by_sample, sample_prop, sep=";")
stat_df <- get_stat(read_count_df, stat_df, stage="FilterChimera", params=params)
###
### FilerRenkonen
###
# Renkonen index:
# PS = summ(min(p1i, p2i))
# p1i = number of reads for variant i in replicate 1 / number of reads in replicate 1
renkonen_distance_quantile = 0.9
outfile <- paste(outdir, "13_FilterRenkonen.csv", sep="")
read_count_df <- FilterRenkonen(read_count_df, outfile=outfile, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilerRenkonen", params=renkonen_distance_quantile)
###
### PoolReplicates
###
digits = 0
outfile <- paste(outdir, "14_PoolReplicates.csv", sep="")
read_count_samples_df <- PoolReplicates(read_count_df, digits=digits, outfile=outfile, sep=sep)
