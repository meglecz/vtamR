outfile <- paste(outdir, "15_PoolReplicates.csv", sep="")
read_count_samples_df <- PoolReplicates(read_count_df, outfile=outfile)
# Run function and get stats
stat_df <- GetStat(read_count_samples_df, stat_df, stage="PoolReplicates")
# Set parameter values
missing_occurrences <- paste(outdir, "missing_occurrences.csv", sep= "")
performance_metrics <- paste(outdir, "performance_metrics.csv", sep= "")
known_occurrences <- paste(outdir, "known_occurrences.csv", sep= "")
sortedinfo <- paste(sorted_dir, "sortedinfo.csv", sep ="")
# Run function
results <- MakeKnownOccurrences(read_count_samples_df, sortedinfo=sortedinfo, mock_composition=mock_composition, known_occurrences=known_occurrences, missing_occurrences=missing_occurrences, performance_metrics=performance_metrics)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
# Set parameter values
outfile <- paste(outdir, "TaxAssign.csv", sep="")
# Run function
asv_tax <- TaxAssign(asv=read_count_samples_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outfile=outfile, num_threads=num_threads)
# write ASV table completed by taxonomic assignments
outfile=paste(outdir, "Final_asvtable_with_TaxAssign.csv", sep="")
asv_table_df <- WriteASVtable(read_count_samples_df, outfile=outfile, asv_tax=asv_tax, sortedinfo=sortedinfo, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition)
write.csv(stat_df, file = paste(outdir, "stat_steps.csv", sep=""))
randomseq_dir = paste(outdir, "random_seq/", sep="")
fastainfo_df <- RandomSeq(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, vsearch_path=vsearch_path, n=10000)
tmp_ASV_27 <- HistoryBy(dir=outdir, feature="asv_id", value="27")
tmp_replicate_1 <- HistoryBy(dir=outdir, feature="asv", value="CCTTTATTTTATTTTCGGTATCTGGTCAGGTCTCGTAGGATCATCACTTAGATTTATTATTCGAATAGAATTAAGAACTCCTGGTAGATTTATTGGCAACGACCAAATTTATAACGTAATTGTTACATCTCATGCATTTATTATAATTTTTTTTATAGTTATACCAATCATAATT")
tmp_sample_tpos1 <- HistoryBy(dir=outdir, feature="sample", value="tpos1")
read_count_by_sample <- SummarizeBy(dir=outdir, feature="read_count", grouped_by="sample")
asv_by_sample <- SummarizeBy(dir=outdir, feature="asv", grouped_by="sample")
asvid_by_replicate <- SummarizeBy(dir=outdir, feature="asv_id", grouped_by="replicate")
library("devtools")
library("roxygen2")
library("seqinr")
library("dplyr")
library("tidyr")
library("ggplot2")
load_all(".")
roxygenise()
usethis::use_roxygen_md()
cutadapt_path <- "C:/Users/Public"
vsearch_path <- "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin"
blast_path <- "C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/Users/Public/swarm-3.1.4-win-x86_64/bin"
vtam_dir <- "C:/Users/emese/vtamR"
setwd(vtam_dir)
num_threads <- 4
sep <- ","
taxonomy <- "C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/COInr_for_vtam"
fastq_dir <- "vtamR_test/data/"
outdir <- "vtamR_test/out_zfzr/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list.csv"
CheckFileinfo(file=fastqinfo, dir=fastq_dir, file_type="fastqinfo")
CheckFileinfo(file=mock_composition, file_type="mock_composition")
CheckFileinfo(file=asv_list, file_type="asv_list")
# merge and quality filter
merged_dir <- paste(outdir, "merged/", sep="")
fastainfo_df <- Merge(fastqinfo, fastq_dir=fastq_dir, vsearch_path=vsearch_path, outdir=merged_dir)
# demultiplex, trim tags and pimers
sorted_dir <- paste(outdir, "sorted/", sep="")
sortedinfo_df <- SortReads(fastainfo_df, fasta_dir=merged_dir, outdir=sorted_dir, check_reverse=TRUE, cutadapt_path=cutadapt_path, vsearch_path=vsearch_path)
outfile <- paste(outdir, "1_before_filter.csv", sep="")
updated_asv_list <- paste(outdir, "ASV_list_with_IDs.csv", sep="")
read_count_df <- Dereplicate(sortedinfo_df, dir=sorted_dir, outfile=outfile, asv_list=asv_list, updated_asv_list=updated_asv_list)
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
stat_df <- GetStat(read_count_df, stat_df, stage="Input", params=NA)
by_sample <- TRUE
outfile <- paste(outdir, "2_Swarm_by_sample.csv", sep="")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, by_sample=by_sample)
stat_df <- GetStat(read_count_df, stat_df, stage="Swarm", params=by_sample)
global_read_count_cutoff = 2
outfile <- paste(outdir, "3_LFNglobalReadCount.csv", sep="")
read_count_df <- LFNglobalReadCount(read_count_df, cutoff=global_read_count_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="LFNglobalReadCount", params=global_read_count_cutoff)
outfile <- paste(outdir, "4_FilterIndel.csv", sep="")
read_count_df <- FilterIndel(read_count_df, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterIndel")
outfile <- paste(outdir, "5_FilterCodonStop.csv", sep="")
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, outfile=outfile, genetic_code=genetic_code)
stat_df <- GetStat(read_count_df, stat_df, stage="FilerCodonStop", params=genetic_code)
abskew=2
by_sample = T
sample_prop = 0.8
outfile <- paste(outdir, "6_FilterChimera.csv", sep="")
read_count_df <- FilterChimera(read_count_df, outfile=outfile, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew)
params <- paste(abskew, by_sample, sample_prop, sep=";")
stat_df <- GetStat(read_count_df, stat_df, stage="FilterChimera", params=params)
# calculate renkonen distance among all replicates within sample
renkonen_within_df <- MakeRenkonenDistances(read_count_df, compare_all=FALSE)
# density plot
renkonen_density_plot <- DensityPlot_RenkonenDistance(renkonen_within_df)
print(renkonen_density_plot)
# barplot
sortedinfo <- paste(sorted_dir, "sortedinfo.csv", sep="")
renkonen_barplot <- Barplot_RenkonenDistance(renkonen_within_df, sample_types=sortedinfo, x_axis_label_size=6)
print(renkonen_barplot)
outfile <- paste(outdir, "7_FilterRenkonen.csv", sep="")
cutoff <- 0.4
read_count_df <- FilterRenkonen(read_count_df, outfile=outfile, cutoff=cutoff)
stat_df <- GetStat(read_count_df, stat_df, stage="FilerRenkonen", params=cutoff)
View(read_count_df)
outfile <- paste(outdir, "ASV_taxa.csv", sep="")
asv_tax <- TaxAssign(asv=read_count_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, num_threads=num_threads, outfile=outfile)
tmp_read_count_samples_df <- PoolReplicates(read_count_df, outfile=outfile, sep=sep)
tmp_asv_table <- WriteASVtable(tmp_read_count_samples_df, sortedinfo=sortedinfo, add_sums_by_asv=T, asv_tax=asv_tax)
asv_tpos1 <- tmp_asv_table %>%
select(tpos1, Total_number_of_reads, Number_of_samples, asv_id, phylum, class, order, family, genus, species, asv) %>%
filter(tpos1 > 0) %>%
arrange(desc(tpos1))
View(asv_tpos1)
outfile <- paste(outdir, "OptimizePCRerror.csv", sep="")
outfile <- paste(outdir, "OptimizePCRerror.csv", sep="")
outfile <- paste(outdir, "OptimizePCRerror.csv", sep="")
OptimizePCRerror_df <- OptimizePCRerror(read_count_df, mock_composition=mock_composition, vsearch_path=vsearch_path, outfile=outfile, max_mismatch=2, min_read_count=5)
View(OptimizePCRerror_df)
pcr_error_var_prop <- 0.05
max_mismatch <- 2
outfile <- paste(outdir, "8_FilterPCRerror.csv", sep="")
read_count_df <- FilterPCRerror(read_count_df, outfile=outfile, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch)
params <- paste(pcr_error_var_prop, max_mismatch, by_sample, sep=";")
stat_df <- GetStat(read_count_df, stat_df, stage="FilterPCRerror", params=params)
outfile = paste(outdir, "OptimizeLFNsampleReplicate.csv", sep="")
OptimizeLFNsampleReplicate_df <- OptimizeLFNsampleReplicate(read_count=read_count_df, mock_composition=mock_composition, outfile=outfile)
View(OptimizeLFNsampleReplicate_df)
lfn_sample_replicate_cutoff <- 0.002
outfile <- paste(outdir, "9_LFNsampleReplicate.csv", sep="")
read_count_df <- LFNsampleReplicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="LFNsampleReplicate", params=lfn_sample_replicate_cutoff)
## LFNvariant
# Set parameter values
min_replicate_number <- 2
outfile <- paste(outdir, "10_FilterMinReplicate.csv", sep="")
# Run filter and get stats
read_count_df <- FilterMinReplicate(read_count_df, min_replicate_number, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterMinReplicate", params=min_replicate_number)
# Pool replicates
read_count_samples_df <- PoolReplicates(read_count_df)
# Detect known occurrences
results <- MakeKnownOccurrences(read_count_samples = read_count_samples_df, sortedinfo=sortedinfo, mock_composition=mock_composition)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
outfile = paste(outdir, "OptimizeLFNreadCountLFNvariant.csv", sep="")
OptimizeLFNreadCountLFNvariant_df <- OptimizeLFNreadCountLFNvariant(read_count_df, known_occurrences=known_occurrences_df, outfile= outfile, min_replicate_number=2)
View(OptimizeLFNreadCountLFNvariant_df)
## LFNvariant
# Set parameter values
lnf_variant_cutoff = 0.001
outfile <- paste(outdir, "11_LFNvariant.csv", sep="")
# Run filter and get stats
read_count_df_lnf_variant <- LFNvariant(read_count_df, cutoff=lnf_variant_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df_lnf_variant, stat_df, stage="LFNvariant", params=lnf_variant_cutoff)
## LFNreadCount
# Set parameter values
lfn_read_count_cutoff <- 10
outfile <- paste(outdir, "12_LFNreadCount.csv", sep="")
# Run filter and get stats
read_count_df_lfn_read_count <- LFNreadCount(read_count_df, cutoff=lfn_read_count_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df_lfn_read_count, stat_df, stage="LFNreadCount", params=lfn_read_count_cutoff)
## Combine results
# Set parameter values
outfile <- paste(outdir, "13_poolLFN.csv", sep="")
# Combine results and get stats
read_count_df <- PoolFilters(read_count_df_lfn_read_count, read_count_df_lnf_variant, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterLFN")
# delete temporary data frames
rm(read_count_df_lfn_read_count)
rm(read_count_df_lnf_variant)
## LFNvariant
# Set parameter values
min_replicate_number <- 2
outfile <- paste(outdir, "14_FilterMinReplicate.csv", sep="")
# Run filter and get stats
read_count_df <- FilterMinReplicate(read_count_df, min_replicate_number, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterMinReplicate", params=min_replicate_number)
# Set parameter values
outfile <- paste(outdir, "15_PoolReplicates.csv", sep="")
read_count_samples_df <- PoolReplicates(read_count_df, outfile=outfile)
# Run function and get stats
stat_df <- GetStat(read_count_samples_df, stat_df, stage="PoolReplicates")
# Set parameter values
missing_occurrences <- paste(outdir, "missing_occurrences.csv", sep= "")
performance_metrics <- paste(outdir, "performance_metrics.csv", sep= "")
known_occurrences <- paste(outdir, "known_occurrences.csv", sep= "")
sortedinfo <- paste(sorted_dir, "sortedinfo.csv", sep ="")
# Run function
results <- MakeKnownOccurrences(read_count_samples_df, sortedinfo=sortedinfo, mock_composition=mock_composition, known_occurrences=known_occurrences, missing_occurrences=missing_occurrences, performance_metrics=performance_metrics)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
# write ASV table completed by taxonomic assignments
outfile=paste(outdir, "Final_asvtable_with_TaxAssign.csv", sep="")
asv_table_df <- WriteASVtable(read_count_samples_df, outfile=outfile, asv_tax=asv_tax, sortedinfo=sortedinfo, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition)
write.csv(stat_df, file = paste(outdir, "stat_steps.csv", sep=""))
View(stat_df)
files <- data.frame(file=c("vtamR_test/out_mfzr/15_PoolReplicates.csv", "vtamR_test/test/15_PoolReplicates_ZFZR.csv"),
marker=c("MFZR", "ZFZR"))
outfile <- paste(outdir, "Pooled_datasets.csv", sep="")
asv_with_centroids <- paste(outdir, "Pooled_datasets_asv_with_centroids.csv", sep="")
read_count_pool <- PoolDatasets(files, outfile=outfile, asv_with_centroids=asv_with_centroids, mean_over_markers=T, vsearch_path=vsearch_path)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
library("devtools")
library("roxygen2")
library("seqinr")
library("dplyr")
library("tidyr")
library("ggplot2")
load_all(".")
roxygenise()
roxygenise()
usethis::use_roxygen_md()
cutadapt_path <- "C:/Users/Public"
vsearch_path <- "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin"
blast_path <- "C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/Users/Public/swarm-3.1.4-win-x86_64/bin"
vtam_dir <- "C:/Users/emese/vtamR"
setwd(vtam_dir)
num_threads <- 4
sep <- ","
taxonomy <- "C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/COInr_for_vtam"
fastq_dir <- "vtamR_test/data/"
outdir <- "vtamR_test/out_mfzr/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr.csv"
mock_composition <- "vtamR_test/data/mock_composition_mfzr.csv"
asv_list <- "vtamR_test/data/asv_list.csv"
?Dereplicate
?Swarm
?OptimizePCRerror
?FilterPCRerror
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
library("devtools")
library("devtools")
library("roxygen2")
library("seqinr")
library("dplyr")
library("tidyr")
library("ggplot2")
load_all(".")
roxygenise()
roxygenise()
usethis::use_roxygen_md()
cutadapt_path <- "C:/Users/Public"
vsearch_path <- "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin"
blast_path <- "C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/Users/Public/swarm-3.1.4-win-x86_64/bin"
vtam_dir <- "C:/Users/emese/vtamR"
setwd(vtam_dir)
num_threads <- 4
sep <- ","
getwd()
taxonomy <- "C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/COInr_for_vtam"
file.exists(taxonomy)
taxonomy <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5/COInr_for_vtam"
file.exists(taxonomy)
file.exists(blast_db)
tmp <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5/"
file.exists(tmp)
tmp <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5"
file.exists(tmp)
tmp <- "C:\Users\Public\COInr_for_vtam_2024_05_06_dbV5"
tmp <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5"
file.exists(taxonomy)
file.exists(tmp)
taxonomy <- file.path("C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5", "COInr_for_vtam_taxonomy.tsv")
file.exists(taxonomy)
taxonomy
taxonomy <- file.path("C:\\Users\\Public\\COInr_for_vtam_2024_05_06_dbV5", "COInr_for_vtam_taxonomy.tsv")
file.exists(taxonomy)
taxonomy
?file.path
tmp <- file.path("C:\\Users\\Public\\","COInr_for_vtam_2024_05_06_dbV5")
tmp
file.exists(tmp)
tmp <- file.path("C:/Users/Public/","COInr_for_vtam_2024_05_06_dbV5")
tmp
file.exists(tmp)
?file.path
taxonomy <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "C:/Users/Public/COInr_for_vtam_2024_05_06_dbV5/COInr_for_vtam"
fastq_dir <- "vtamR_test/data/"
outdir <- "vtamR_test/out_mfzr/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr.csv"
mock_composition <- "vtamR_test/data/mock_composition_mfzr.csv"
asv_list <- "vtamR_test/data/asv_list.csv"
CheckFileinfo(file=fastqinfo, dir=fastq_dir, file_type="fastqinfo")
CheckFileinfo(file=mock_composition, file_type="mock_composition")
CheckFileinfo(file=asv_list, file_type="asv_list")
merged_dir <- file.path(outdir, "merged/")
merged_dir
fastainfo_df <- Merge(fastqinfo, fastq_dir=fastq_dir, vsearch_path=vsearch_path, outdir=merged_dir)
outdir
outdir <- "vtamR_test/out_mfzr"
merged_dir <- file.path(outdir, "merged/")
fastainfo_df <- Merge(fastqinfo, fastq_dir=fastq_dir, vsearch_path=vsearch_path, outdir=merged_dir)
vtam_dir <- "C:/Users/emese/vtamR/"
setwd(vtam_dir)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
### windows
cutadapt_path <- "C:/Users/Public/"
vsearch_path <- "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path <- "C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/Users/Public/swarm-3.1.4-win-x86_64/bin/"
num_threads <- 4
sep <- ","
library("devtools")
library("devtools")
library("roxygen2")
library("seqinr")
library("dplyr")
library("tidyr")
library("ggplot2")
load_all(".")
roxygenise()
roxygenise()
usethis::use_roxygen_md()
Test_MergeSortReads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
Test_Filters(vsearch_path=vsearch_path, swarm_path=swarm_path)
Test_Filters(vsearch_path=vsearch_path, swarm_path=swarm_path, quiet=FALSE)
swarm_path <- "C:/Users/Public/swarm-3.1.5-win-x86_64/bin/"
Test_Filters(vsearch_path=vsearch_path, swarm_path=swarm_path, quiet=FALSE)
Test_MakeKnownOccurrences()
Test_Optimize(vsearch_path=vsearch_path)
Test_TaxAssign(blast_path=blast_path, num_threads=num_threads)
blast_path <- "C:/Users/Public/blast-2.16.0+/bin/"
Test_TaxAssign(blast_path=blast_path, num_threads=num_threads)
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, chache=TRUE )
# Windows
cutadapt_path <- "C:/Users/Public/"
vsearch_path <- "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path <- "C:/Users/Public/blast-2.16.0+/bin/"
swarm_path <- "C:/Users/Public/swarm-3.1.5-win-x86_64/bin/"
num_threads <- 4
sep <- ","
taxonomy <- "C:/Users/Public/COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "C:/Users/Public/COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam"
fastq_dir <- "vtamR_test/data"
outdir <- "vtamR_test/out_mfzr"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr.csv"
mock_composition <- "vtamR_test/data/mock_composition_mfzr.csv"
asv_list <- "vtamR_test/data/asv_list.csv"
CheckFileinfo(file=fastqinfo, dir=fastq_dir, file_type="fastqinfo")
CheckFileinfo(file=mock_composition, file_type="mock_composition")
CheckFileinfo(file=asv_list, file_type="asv_list")
# merge and quality filter
merged_dir <- file.path(outdir, "merged")
fastainfo_df <- Merge(fastqinfo, fastq_dir=fastq_dir, vsearch_path=vsearch_path, outdir=merged_dir)
fastainfo_df <- Merge(fastqinfo, fastq_dir=fastq_dir, vsearch_path=vsearch_path, outdir=merged_dir)
# demultiplex, trim tags and pimers
sorted_dir <- file.path(outdir, "sorted")
sortedinfo_df <- SortReads(fastainfo_df, fasta_dir=merged_dir, outdir=sorted_dir, check_reverse=TRUE, cutadapt_path=cutadapt_path, vsearch_path=vsearch_path)
outfile <- file.path(outdir, "1_before_filter.csv")
updated_asv_list <- file.path(outdir, "ASV_list_with_IDs.csv")
read_count_df <- Dereplicate(sortedinfo_df, dir=sorted_dir, outfile=outfile, asv_list=asv_list, updated_asv_list=updated_asv_list)
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
stat_df <- GetStat(read_count_df, stat_df, stage="Input", params=NA)
by_sample <- TRUE
outfile <- file.path(outdir, "2_Swarm_by_sample.csv")
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, by_sample=by_sample)
read_count_df <- Swarm(read_count_df, outfile=outfile, swarm_path=swarm_path, num_threads=num_threads, by_sample=by_sample)
stat_df <- GetStat(read_count_df, stat_df, stage="Swarm", params=by_sample)
global_read_count_cutoff = 2
outfile <- file.path(outdir, "3_LFNglobalReadCount.csv")
read_count_df <- LFNglobalReadCount(read_count_df, cutoff=global_read_count_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="LFNglobalReadCount", params=global_read_count_cutoff)
outfile <- file.path(outdir, "4_FilterIndel.csv")
read_count_df <- FilterIndel(read_count_df, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterIndel")
outfile <- file.path(outdir, "5_FilterCodonStop.csv")
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, outfile=outfile, genetic_code=genetic_code)
abskew=2
by_sample = T
sample_prop = 0.8
outfile <- file.path(outdir, "6_FilterChimera.csv")
read_count_df <- FilterChimera(read_count_df, outfile=outfile, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew)
read_count_df <- FilterChimera(read_count_df, outfile=outfile, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew)
params <- paste(abskew, by_sample, sample_prop, sep=";")
params <- paste(abskew, by_sample, sample_prop, sep=";")
stat_df <- GetStat(read_count_df, stat_df, stage="FilterChimera", params=params)
# calculate renkonen distance among all replicates within sample
renkonen_within_df <- MakeRenkonenDistances(read_count_df, compare_all=FALSE)
# density plot
renkonen_density_plot <- DensityPlot_RenkonenDistance(renkonen_within_df)
print(renkonen_density_plot)
# barplot
sortedinfo <- file.path(sorted_dir, "sortedinfo.csv")
renkonen_barplot <- Barplot_RenkonenDistance(renkonen_within_df, sample_types=sortedinfo, x_axis_label_size=6)
print(renkonen_barplot)
outfile <- file.path(outdir, "7_FilterRenkonen.csv")
cutoff <- 0.4
read_count_df <- FilterRenkonen(read_count_df, outfile=outfile, cutoff=cutoff)
stat_df <- GetStat(read_count_df, stat_df, stage="FilerRenkonen", params=cutoff)
outfile <- file.path(outdir, "ASV_taxa.csv")
asv_tax <- TaxAssign(asv=read_count_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, num_threads=num_threads, outfile=outfile)
outfile <- file.path(outdir, "ASV_taxa.csv")
asv_tax <- TaxAssign(asv=read_count_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, num_threads=num_threads, outfile=outfile)
outfile <- file.path(outdir, "ASV_taxa.csv")
asv_tax <- TaxAssign(asv=read_count_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, num_threads=num_threads, outfile=outfile)
asv_tax <- TaxAssign(asv=read_count_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, num_threads=num_threads, outfile=outfile)
tmp_read_count_samples_df <- PoolReplicates(read_count_df, outfile=outfile, sep=sep)
sortedinfo <- file.path(sorted_dir, "sortedinfo.csv")
tmp_asv_table <- WriteASVtable(tmp_read_count_samples_df, sortedinfo=sortedinfo, add_sums_by_asv=T, asv_tax=asv_tax)
asv_tpos1 <- tmp_asv_table %>%
select(tpos1, Total_number_of_reads, Number_of_samples, asv_id, phylum, class, order, family, genus, species, asv) %>%
filter(tpos1 > 0) %>%
arrange(desc(tpos1))
outfile <- file.path(outdir, "OptimizePCRerror.csv")
OptimizePCRerror_df <- OptimizePCRerror(read_count_df, mock_composition=mock_composition, vsearch_path=vsearch_path, outfile=outfile, max_mismatch=2, min_read_count=5)
outfile <- file.path(outdir, "OptimizePCRerror.csv")
OptimizePCRerror_df <- OptimizePCRerror(read_count_df, mock_composition=mock_composition, vsearch_path=vsearch_path, outfile=outfile, max_mismatch=2, min_read_count=5)
pcr_error_var_prop <- 0.05
max_mismatch <- 2
outfile <- file.path(outdir, "8_FilterPCRerror.csv")
read_count_df <- FilterPCRerror(read_count_df, outfile=outfile, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch)
read_count_df <- FilterPCRerror(read_count_df, outfile=outfile, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch)
params <- paste(pcr_error_var_prop, max_mismatch, by_sample, sep=";")
stat_df <- GetStat(read_count_df, stat_df, stage="FilterPCRerror", params=params)
outfile = file.path(outdir, "OptimizeLFNsampleReplicate.csv")
OptimizeLFNsampleReplicate_df <- OptimizeLFNsampleReplicate(read_count=read_count_df, mock_composition=mock_composition, outfile=outfile)
lfn_sample_replicate_cutoff <- 0.004
outfile <- file.path(outdir, "9_LFNsampleReplicate.csv")
read_count_df <- LFNsampleReplicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="LFNsampleReplicate", params=lfn_sample_replicate_cutoff)
# Set parameter values
min_replicate_number <- 2
outfile <- file.path(outdir, "10_FilterMinReplicate.csv")
# Run filter and get stats
read_count_df <- FilterMinReplicate(read_count_df, min_replicate_number, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterMinReplicate", params=min_replicate_number)
# Pool replicates
read_count_samples_df <- PoolReplicates(read_count_df)
# Detect known occurrences
results <- MakeKnownOccurrences(read_count_samples = read_count_samples_df, sortedinfo=sortedinfo, mock_composition=mock_composition)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
outfile = file.path(outdir, "OptimizeLFNreadCountLFNvariant.csv")
OptimizeLFNreadCountLFNvariant_df <- OptimizeLFNreadCountLFNvariant(read_count_df, known_occurrences=known_occurrences_df, outfile= outfile, min_replicate_number=2)
## LFNvariant
# Set parameter values
lnf_variant_cutoff = 0.001
outfile <- file.path(outdir, "11_LFNvariant.csv")
# Run filter and get stats
read_count_df_lnf_variant <- LFNvariant(read_count_df, cutoff=lnf_variant_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df_lnf_variant, stat_df, stage="LFNvariant", params=lnf_variant_cutoff)
View(stat_df)
## LFNreadCount
# Set parameter values
lfn_read_count_cutoff <- 10
outfile <- file.path(outdir, "12_LFNreadCount.csv")
# Run filter and get stats
read_count_df_lfn_read_count <- LFNreadCount(read_count_df, cutoff=lfn_read_count_cutoff, outfile=outfile)
stat_df <- GetStat(read_count_df_lfn_read_count, stat_df, stage="LFNreadCount", params=lfn_read_count_cutoff)
## Combine results
# Set parameter values
outfile <- file.path(outdir, "13_poolLFN.csv")
# Combine results and get stats
read_count_df <- PoolFilters(read_count_df_lfn_read_count, read_count_df_lnf_variant, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterLFN")
# delete temporary data frames
rm(read_count_df_lfn_read_count)
rm(read_count_df_lnf_variant)
# Set parameter values
min_replicate_number <- 2
outfile <- file.path(outdir, "14_FilterMinReplicate.csv")
# Run filter and get stats
read_count_df <- FilterMinReplicate(read_count_df, min_replicate_number, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterMinReplicate", params=min_replicate_number)
# Set parameter values
outfile <- file.path(outdir, "15_PoolReplicates.csv")
read_count_samples_df <- PoolReplicates(read_count_df, outfile=outfile)
# Run function and get stats
stat_df <- GetStat(read_count_samples_df, stat_df, stage="PoolReplicates")
# Set parameter values
missing_occurrences <- file.path(outdir, "missing_occurrences.csv")
performance_metrics <- file.path(outdir, "performance_metrics.csv")
known_occurrences <- file.path(outdir, "known_occurrences.csv")
sortedinfo <- file.path(sorted_dir, "sortedinfo.csv")
# Run function
results <- MakeKnownOccurrences(read_count_samples_df, sortedinfo=sortedinfo, mock_composition=mock_composition, known_occurrences=known_occurrences, missing_occurrences=missing_occurrences, performance_metrics=performance_metrics)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
# Set parameter values
outfile <- file.path(outdir, "TaxAssign.csv")
# Run function
asv_tax <- TaxAssign(asv=read_count_samples_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outfile=outfile, num_threads=num_threads)
# write ASV table completed by taxonomic assignments
outfile=file.path(outdir, "Final_asvtable_with_TaxAssign.csv")
asv_table_df <- WriteASVtable(read_count_samples_df, outfile=outfile, asv_tax=asv_tax, sortedinfo=sortedinfo, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition)
write.csv(stat_df, file = file.path(outdir, "stat_steps.csv"))
randomseq_dir = file.path(outdir, "random_seq")
fastainfo_df <- RandomSeq(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, vsearch_path=vsearch_path, n=10000)
