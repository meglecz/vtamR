by_replicate = TRUE
read_count_df_lnf_variant <- LFN_variant(read_count_df, lnf_variant_cutoff, by_replicate, write_csv=F, outdir = outdir)
param_values <- paste(lnf_variant_cutoff, by_replicate, sep=";")
stat_df <- get_stat(read_count_df_lnf_variant, stat_df, stage="LFN_variant", params=param_values)
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
read_count_df <- pool_LFN(read_count_df_lfn_read_count, read_count_df_lnf_variant, read_count_df_lnf_sample_replicate, write_csv=T, outdir = outdir)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterLFN")
# delete temporary data frames
read_count_df_lfn_read_count <- NULL
read_count_df_lnf_variant <- NULL
read_count_df_lnf_sample_replicate <- NULL
###
### keep repeatable occurrences
###
min_relicate_number = 2
read_count_df <- FilterMinReplicateNumber(read_count_df, min_relicate_number, write_csv=F, outdir = outdir)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterMinReplicateNumber", params=min_relicate_number)
###
### FilerIndel
###
read_count_df <- FilterIndel(read_count_df, write_csv=F, outdir=outdir)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterIndel")
###
### FilerCodonStop
###
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, write_csv=F, outdir=outdir, genetic_code=genetic_code)
stat_df <- get_stat(read_count_df, stat_df, stage="FilerCodonStop", params=genetic_code)
temp_df <- read_count_df
View(stat_df)
View(temp_df)
####
# define input filenames
fastqdir <- "local/small_test"
fileinfo <- "local/user_input/fileinfo_small.csv"
####
# define input filenames
fastqdir <- "local/small_test"
fileinfo <- "local/user_input/fileinfo_small.csv"
# create the output directory and check the the slash at the end
outdir <- check_dir(dir="local/out/small")
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
# read input fasta files in fileinfo, demultiplex and count the number of reads in each plate-sample-replicate
read_count_df <- read_fastas_from_fileinfo(file=fileinfo, dir=fastqdir, write_csv=F, outdir=outdir)
# make stat counts
stat_df <- get_stat(read_count_df, stat_df, stage="Input", params=NA)
temp_df <- read_count_df
# create a tmp directory for temporary files
outdir_tmp <- paste(outdir, 'tmp_', trunc(as.numeric(Sys.time())), sep='')
outdir_tmp <- check_dir(outdir_tmp)
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
fas <- paste(outdir_tmp, 'unique.fas', sep="")
blastout <- paste(outdir_tmp, 'unique_blastout.out', sep="")
create_fasta_file <- function(sequences, filename) {
# Open the file for writing
file <- file(filename, "w")
# Iterate over the sequences and write them to the file
for (i in seq_along(sequences)) {
header <- paste0(">Seq", i)
sequence <- sequences[[i]]
writeLines(c(header, sequence, ""), file)
}
# Close the file
close(file)
}
temp_df <- read_count_df
View(temp_df)
create_fasta_file(unique_asv_df$asv, fas)
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --blast6out ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --blast6out ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+alnlen+ids' --blast6out ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+alnlen+ids' --userout ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+alnlen+ids+qrow+trow' --userout ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+alnlen+ids+aln' --userout ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+id+alnlen+ids+aln' --userout ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+id+qhi+thi+alnlen+ids+aln' --userout ", blastout, sep="")
--userfields query+target+alnlen+ids
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+id+qhi+thi+alnlen+ids+aln' --userout ", blastout, sep="")
vsearch
setwd("~/vtamR")
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
####
# define input filenames
fastqdir <- "local/small_test"
fileinfo <- "local/user_input/fileinfo_small.csv"
# create the output directory and check the the slash at the end
outdir <- check_dir(dir="local/out/small")
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
# read input fasta files in fileinfo, demultiplex and count the number of reads in each plate-sample-replicate
read_count_df <- read_fastas_from_fileinfo(file=fileinfo, dir=fastqdir, write_csv=F, outdir=outdir)
# make stat counts
stat_df <- get_stat(read_count_df, stat_df, stage="Input", params=NA)
temp_df <- read_count_df
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
fas <- paste(outdir_tmp, 'unique.fas', sep="")
blastout <- paste(outdir_tmp, 'unique_blastout.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+id+qhi+thi+alnlen+ids+aln' --userout ", blastout, sep="")
vsearch
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", blastout, sep="")
vsearch
myPipe <- pipe(vsearch)
results <- read.table( myPipe )
myPipe <- pipe("blastn –db local/out/small/tmp_1687945245/test.fas –query local/out/small/tmp_1687945245/test.fas –outfmt 6 –out local/out/small/tmp_1687945245/test_blastout.out")
results <- read.table( myPipe )
myPipe <- pipe("blastn -db local/out/small/tmp_1687945245/test.fas -query local/out/small/tmp_1687945245/test.fas -outfmt 6 -out local/out/small/tmp_1687945245/test_blastout.out")
results <- read.table( myPipe )
myPipe
myPipe <- pipe("blastn -db local/out/small/tmp_1687945245/test.fas -query local/out/small/tmp_1687945245/test.fas -outfmt 6")
myPipe
results <- read.table( myPipe )
results
colnames( blastResults ) <- c( "QueryID",  "SubjectID", "Perc.Ident",
"Alignment.Length", "Mismatches", "Gap.Openings", "Q.start", "Q.end",
"S.start", "S.end", "E", "Bits" )
colnames( results ) <- c( "QueryID",  "SubjectID", "Perc.Ident",
"Alignment.Length", "Mismatches", "Gap.Openings", "Q.start", "Q.end",
"S.start", "S.end", "E", "Bits" )
View(results)
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln'", sep="")
myPipe_vsearch <- pipe(vsearch)
results <- read.table( myPipe_vsearch )
blast <- "blastn -db local/out/small/tmp_1687945245/test.fas -query local/out/small/tmp_1687945245/test.fas -outfmt 6"
myPipe <- pipe(blast)
results <- read.table( myPipe )
colnames( results ) <- c( "QueryID",  "SubjectID", "Perc.Ident",
"Alignment.Length", "Mismatches", "Gap.Openings", "Q.start", "Q.end",
"S.start", "S.end", "E", "Bits" )
View(results)
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln'", sep="")
myPipe_vsearch <- pipe(vsearch)
results <- read.table( myPipe_vsearch )
results
rm(results)
myPipe_vsearch <- pipe(vsearch)
results <- read.table( myPipe_vsearch )
results
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln'", sep="")
vsearch
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln'", sep="")
vsearch
pipe_vsearch <- pipe(vsearch)
results <- read.table( pipe_vsearch )
results <- read.table( pipe_vsearch )
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", blastout, sep="")
vsearch
pipe_vsearch <- pipe(vsearch)
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
pipe_vsearch <- pipe(vsearch)
vsearch
system("ls -F")
temp <- system("ls -F")
temp <- system("ls -F")
temp
# vsearch all seq against all to find similar sequences
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE)
View(results_vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
View(results_vsearch)
results_vsearch$alnlen <- nbchar(results_vsearch$aln)
results_vsearch$alnlen <- nb_char(results_vsearch$aln)
results_vsearch$alnlen <- nchar(results_vsearch$aln)
View(results_vsearch)
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
View(results_vsearch)
results_vsearch$alnlen <- nchar(results_vsearch$aln)
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
max_mismatch = 1
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
create_fasta_file <- function(sequences, filename) {
# Open the file for writing
file <- file(filename, "w")
# Iterate over the sequences and write them to the file
for (i in seq_along(sequences)) {
header <- paste0(">", sequences[[i]])
writeLines(c(header, sequences[[i]], ""), file)
}
# Close the file
close(file)
}
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
# keep only pairs with max_mismatch differrences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
rm(results_vsearch$nb_ids)
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
select(results_vsearch, -c(nb_ids, aln))
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
View(results_vsearch)
View(results_vsearch)
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
select(results_vsearch, -c(nb_ids, aln))
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by=asv)
View(unique_asv_df)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
###
### FilerPCRerror
###
pcr_error_var_prop = 0.1
rownames(unique_asv_df) <- unique_asv_df$asv
unique_asv_df$PCRerror <- rep(0, length(unique_asv_df$asv))
rownames(unique_asv_df) <- unique_asv_df$asv
for(i in 1:length(results_vsearch$qasv)){
if((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count){
unique_asv_df[results_vsearch$tasv, PCRerror] <- 1
}
}
for(i in 1:length(results_vsearch$qasv)){
if((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count){
unique_asv_df[results_vsearch$tasv, "PCRerror"] <- 1
}
}
results_vsearch$PCRerror <- (results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
results_vsearch$PCRerror <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
results_vsearch$PCRerror_target <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
unique_asv_df$PCRerror <- rep(0, length(unique_asv_df$asv))
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
results_vsearch$PCRerror_target <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
results_vsearch$PCRerror_target <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
results_vsearch <- select(results_vsearch$PCRerror_target==TRUE)
results_vsearch <- results_vsearch %>%
select(PCRerror_target==TRUE)
# get unique list of ASVs with their total read_count in the run
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
results_vsearch$PCRerror_target <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
results_vsearch <- results_vsearch %>%
filter(PCRerror_target==TRUE)
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
results_vsearch$PCRerror_target <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
results_vsearch <- results_vsearch %>%
filter(PCRerror_target==TRUE) %>%
group_by(tasv)
unique_asv_df <- read_count_df %>%
group_by(asv) %>%
summarize(read_count = sum(read_count)) %>%
arrange(desc(read_count))
# make fasta file with unique reads
fas <- paste(outdir_tmp, 'unique.fas', sep="")
vsearch_out <- paste(outdir_tmp, 'unique_vsearch_out.out', sep="")
create_fasta_file(unique_asv_df$asv, fas)
# vsearch --usearch_global to find highly similar sequence pairs
vsearch <- paste("vsearch --usearch_global ", fas, " --db ", fas, " --iddef 1 --self --id 0.90 --maxaccepts 0 --maxrejects 0 --userfields 'query+target+ids+aln' --userout ", vsearch_out, sep="")
#https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/system
system(vsearch)
results_vsearch<- read.csv(vsearch_out, header = FALSE, sep="\t")
colnames(results_vsearch) <- c("query","target","nb_ids","aln")
# non of the values easily outputted by vsearch take into the extenal gaps as a diff => correct this based on the alnlen and the number of identities
results_vsearch$nb_diff <- nchar(results_vsearch$aln) - results_vsearch$nb_ids
results_vsearch <- select(results_vsearch, -c(nb_ids, aln))
# keep only pairs with max_mismatch differences
results_vsearch <- results_vsearch %>%
filter(nb_diff <= max_mismatch)
results_vsearch <- rename(results_vsearch, asv = query)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, qasv = asv)
results_vsearch <- rename(results_vsearch, asv = target)
results_vsearch <- rename(results_vsearch, qread_count = read_count)
results_vsearch <- left_join(results_vsearch, unique_asv_df, by="asv")
results_vsearch <- rename(results_vsearch, tread_count = read_count)
results_vsearch <- rename(results_vsearch, tasv = asv)
results_vsearch$PCRerror_target <- ((results_vsearch$qread_count * pcr_error_var_prop) > results_vsearch$tread_count)
results_vsearch <- results_vsearch %>%
filter(PCRerror_target==TRUE) %>%
group_by(tasv) %>%
select(tasv)
