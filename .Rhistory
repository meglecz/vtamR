genetic_code=genetic_code)
### FilterChimera
abskew=2
by_sample = T
sample_prop = 0.8
read_count_df <- FilterChimera(read_count_df,
vsearch_path=vsearch_path,
by_sample=by_sample,
sample_prop=sample_prop,
abskew=abskew)
#### FilterRenkonen
cutoff <- 0.4
read_count_df <- FilterRenkonen(read_count_df,
cutoff=cutoff)
### FilterPCRerror
pcr_error_var_prop <- 0.05
max_mismatch <- 2
read_count_df <- FilterPCRerror(read_count_df,
vsearch_path=vsearch_path,
pcr_error_var_prop=pcr_error_var_prop,
max_mismatch=max_mismatch)
### LFNsampleReplicate
lfn_sample_replicate_cutoff <- 0.004
read_count_df <- LFNsampleReplicate(read_count_df,
cutoff=lfn_sample_replicate_cutoff)
### FilterMinReplicate
min_replicate_number <- 2
read_count_df <- FilterMinReplicate(read_count_df,
cutoff=min_replicate_number)
### LFNvariant
lnf_variant_cutoff = 0.001
read_count_df_lnf_variant <- LFNvariant(read_count_df,
cutoff=lnf_variant_cutoff)
### LFNreadCount
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFNreadCount(read_count_df,
cutoff=lfn_read_count_cutoff)
### Combine results
read_count_df <- PoolFilters(read_count_df_lfn_read_count,
read_count_df_lnf_variant)
# delete temporary data frames
rm(read_count_df_lfn_read_count)
rm(read_count_df_lnf_variant)
### FilterMinReplicate
min_replicate_number <- 2
read_count_df <- FilterMinReplicate(read_count_df,
cutoff=min_replicate_number)
#### PoolReplicates
read_count_samples_df <- PoolReplicates(read_count_df)
### MakeKnownOccurrences performance_metrics
results <- MakeKnownOccurrences(read_count_samples_df,
sortedinfo=sortedinfo_df,
mock_composition=mock_composition)
### TaxAssign
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads)
View(read_count_samples_df)
View(asv_tax)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
### TaxAssign
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads)
### WriteASVtable
outfile=file.path(outdir, "Final_asvtable_with_TaxAssign.csv")
asv_table_df <- WriteASVtable(read_count_samples_df,
outfile=outfile,
asv_tax=asv_tax,
sortedinfo=sortedinfo_df,
add_empty_samples=T,
add_sums_by_sample=T,
add_sums_by_asv=T,
add_expected_asv=T,
mock_composition=mock_composition)
?Dereplicate
### Merge
merged_dir <- file.path(outdir, "merged")
fastainfo_df <- Merge(fastqinfo,
fastq_dir=fastq_dir,
vsearch_path=vsearch_path,
outdir=merged_dir,
fastq_maxee=1,
fastq_maxns=0,
fastq_allowmergestagger=F
)
sorted_dir <- file.path(outdir, "sorted")
sortedinfo_df <- SortReads(fastainfo_df,
fasta_dir=merged_dir,
outdir=sorted_dir,
check_reverse=TRUE,
cutadapt_path=cutadapt_path,
vsearch_path=vsearch_path
)
###############
### dereplicate
###############
updated_asv_list <- fila.path(outdir, "updated_asv_list.tsv")
read_count_df <- Dereplicate(sortedinfo_df,
dir=sorted_dir,
asv_list=asv_list,
updated_asv_list =
)
###############
### dereplicate
###############
updated_asv_list <- file.path(outdir, "updated_asv_list.tsv")
read_count_df <- Dereplicate(sortedinfo_df,
dir=sorted_dir,
asv_list=asv_list,
updated_asv_list =
)
read_count_df <- Dereplicate(sortedinfo_df,
dir=sorted_dir,
asv_list=asv_list,
updated_asv_list = updated_asv_list
)
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
stat_df <- GetStat(read_count_df, stat_df, stage="input_sample_replicate", params=NA)
#### swarm
by_sample <- TRUE
read_count_df <- Swarm(read_count_df,
swarm_path=swarm_path,
num_threads=num_threads,
by_sample=by_sample)
#### LFNglobalReadCount
global_read_count_cutoff = 2
read_count_df <- LFNglobalReadCount(read_count_df,
cutoff=global_read_count_cutoff)
#### FilterIndel
read_count_df <- FilterIndel(read_count_df)
### FilterCodonStop
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df,
genetic_code=genetic_code)
### FilterChimera
abskew=2
by_sample = T
sample_prop = 0.8
read_count_df <- FilterChimera(read_count_df,
vsearch_path=vsearch_path,
by_sample=by_sample,
sample_prop=sample_prop,
abskew=abskew)
#### FilterRenkonen
cutoff <- 0.4
read_count_df <- FilterRenkonen(read_count_df,
cutoff=cutoff)
### FilterPCRerror
pcr_error_var_prop <- 0.05
max_mismatch <- 2
read_count_df <- FilterPCRerror(read_count_df,
vsearch_path=vsearch_path,
pcr_error_var_prop=pcr_error_var_prop,
max_mismatch=max_mismatch)
### LFNsampleReplicate
lfn_sample_replicate_cutoff <- 0.004
read_count_df <- LFNsampleReplicate(read_count_df,
cutoff=lfn_sample_replicate_cutoff)
### FilterMinReplicate
min_replicate_number <- 2
read_count_df <- FilterMinReplicate(read_count_df,
cutoff=min_replicate_number)
### LFNvariant
lnf_variant_cutoff = 0.001
read_count_df_lnf_variant <- LFNvariant(read_count_df,
cutoff=lnf_variant_cutoff)
### LFNreadCount
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFNreadCount(read_count_df,
cutoff=lfn_read_count_cutoff)
### Combine results
read_count_df <- PoolFilters(read_count_df_lfn_read_count,
read_count_df_lnf_variant)
# delete temporary data frames
rm(read_count_df_lfn_read_count)
rm(read_count_df_lnf_variant)
### FilterMinReplicate
min_replicate_number <- 2
read_count_df <- FilterMinReplicate(read_count_df,
cutoff=min_replicate_number)
#### PoolReplicates
read_count_samples_df <- PoolReplicates(read_count_df)
### MakeKnownOccurrences performance_metrics
results <- MakeKnownOccurrences(read_count_samples_df,
sortedinfo=sortedinfo_df,
mock_composition=mock_composition)
updated_asv_list <- file.path(outdir, "updated_asv_list_end.tsv")
updated_asv_list <- file.path(outdir, "updated_asv_list_end.tsv")
UpdateASVlist(read_count_samples_df,
asv_list=asv_list,
outfile=updated_asv_list
)
UpdateASVlist(asv_list1 = read_count_samples_df,
asv_list2 =asv_list,
outfile=updated_asv_list
)
df <- UpdateASVlist(asv_list1 = read_count_samples_df,
asv_list2 =asv_list,
outfile=updated_asv_list
)
### TaxAssign
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads)
### WriteASVtable
outfile=file.path(outdir, "Final_asvtable_with_TaxAssign.csv")
asv_table_df <- WriteASVtable(read_count_samples_df,
outfile=outfile,
asv_tax=asv_tax,
sortedinfo=sortedinfo_df,
add_empty_samples=T,
add_sums_by_sample=T,
add_sums_by_asv=T,
add_expected_asv=T,
mock_composition=mock_composition)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
updated_asv_list <- file.path(outdir, "updated_asv_list_end.tsv")
df <- UpdateASVlist(asv_list1 = read_count_samples_df,
asv_list2 =asv_list,
outfile=updated_asv_list
)
UpdateASVlist(asv_list1 = read_count_samples_df,
asv_list2 =asv_list,
outfile=updated_asv_list
)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
updated_asv_list <- file.path(outdir, "updated_asv_list_end.tsv")
UpdateASVlist(asv_list1 = read_count_samples_df,
asv_list2 =asv_list,
outfile=updated_asv_list
)
### MakeKnownOccurrences performance_metrics
results <- MakeKnownOccurrences(read_count_samples_df,
sortedinfo=sortedinfo_df,
mock_composition=mock_composition)
ko <- results[[1]]
View(ko)
View(asv_tax)
out_tax <- file.path(outdir, "taxonomy.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
out_tax <- file.path(outdir, "taxonomy.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
out_tax <- file.path(outdir, "taxonomy.csv")
out_tax
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE)
View(asv_tax)
View(asv_table_df)
View(fastainfo_df)
View(read_count_df)
View(read_count_samples_df)
df
View(df)
tmp <- df %>%
mutate(t=NA)
View(tmp)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
out_tax <- file.path(outdir, "taxonomy.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
out_tax <- file.path(outdir, "taxonomy.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE)
View(df)
asv_df <- df
View(asv_df)
asv_df <- asv_df %>%
select(asv_id, asv) %>%
distinct() %>%
arrange(asv_id)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#### Read taxonomy info
# read taxonomy file;
# quote="" is important, since some of the taxon names have quotes and this should be ignored
tax_df <- read.delim(taxonomy, header=T, sep=tax_sep, fill=T, quote="") %>%
select(tax_id, parent_tax_id, rank, name_txt, old_tax_id, taxlevel)
tax_sep = "\t"
#### Read taxonomy info
# read taxonomy file;
# quote="" is important, since some of the taxon names have quotes and this should be ignored
tax_df <- read.delim(taxonomy, header=T, sep=tax_sep, fill=T, quote="") %>%
select(tax_id, parent_tax_id, rank, name_txt, old_tax_id, taxlevel)
# make data frame with old taxids as line numbers and taxids in a columns
old_taxid <- tax_df %>%
filter(!is.na(old_tax_id)) %>%
select(tax_id, old_tax_id)
# delete old_tax_ids from tax_df and make taxids unique
tax_df <- tax_df %>%
select(-old_tax_id)
tax_df <- unique(tax_df)
View(tax_df)
####
# create a tmp directory for temporary files using time and a random number
outdir_tmp <- paste('tmp_TaxAssign_',
trunc(as.numeric(Sys.time())),
sample(1:100, 1),
sep=''
)
outdir_tmp <- file.path(tempdir(), outdir_tmp)
check_dir(outdir_tmp)
### run blast and clean/complete results
# run blast and read read results to data frame
# (blast_res columns: "qseqid","pident","qcovhsp","staxids")
# Query seqid are arbitrary numbers, do not correspond to asv_id
blast_res <- run_blast(asv_df,
blast_db=blast_db,
blast_path=blast_path,
outdir=outdir_tmp,
qcov_hsp_perc=min(ltg_params_df$pcov),
perc_identity=min(ltg_params_df$pid),
num_threads=num_threads,
quiet=quiet
)
quiet = FALSE
### run blast and clean/complete results
# run blast and read read results to data frame
# (blast_res columns: "qseqid","pident","qcovhsp","staxids")
# Query seqid are arbitrary numbers, do not correspond to asv_id
blast_res <- run_blast(asv_df,
blast_db=blast_db,
blast_path=blast_path,
outdir=outdir_tmp,
qcov_hsp_perc=min(ltg_params_df$pcov),
perc_identity=min(ltg_params_df$pid),
num_threads=num_threads,
quiet=quiet
)
# add update old taxids to valid ones
blast_res <- update_taxids(blast_res, old_taxid)
View(blast_res)
# add taxlevel
blast_res <- left_join(blast_res, tax_df, by=c("staxids" = "tax_id")) %>%
select(-parent_tax_id, -rank, -name_txt) # "qseqid"   "pident"   "qcovhsp"  "staxids"  "taxlevel"
### make a lineage for each taxid in blast_res
lineages <- get_lineage_ids(unique(blast_res$staxids), tax_df)
View(lineages)
taxres_df <- asv_df %>%
mutate(ltg_taxid = NA,
pid=NA,
pcov=NA,
phit=NA,
taxn=NA,
seqn=NA,
refres=NA,
ltgres=NA)
View(taxres_df)
i=1
p=1
pidl <- ltg_params_df[p,"pid"]
pcovl <- ltg_params_df[p,"pcov"]
phitl <- ltg_params_df[p,"phit"]
taxnl <- ltg_params_df[p,"taxn"]
seqnl <- ltg_params_df[p,"seqn"]
refresl <- ltg_params_df[p,"refres"]
ltgresl <- ltg_params_df[p,"ltgres"]
# filter the blastres according to qseqid,  pid, pcov, refres
df_intern <- blast_res %>%
filter(qseqid==taxres_df$asv_id[i] & pident>=pidl & qcovhsp>=pcovl & taxlevel>=refresl)
View(df_intern)
# check if enough taxa and seq among validated hits
tn <- length(unique(df_intern$staxids))
if(tn >= taxnl & nrow(df_intern) >= seqnl ){
# make ltg if all conditions are met
ltg <- make_ltg(df_intern$staxids, lineages, phit = phitl)
# fill out line with the ltg and the parmeters that were used to get it
taxres_df[i, 3:(ncol(taxres_df))] <-
c(ltg, pidl, pcovl, phitl, taxnl, seqnl, refresl, ltgresl)
break
} # end if
# make ltg if all conditions are met
ltg <- make_ltg(df_intern$staxids, lineages, phit = phitl)
ltg
# fill out line with the ltg and the parmeters that were used to get it
taxres_df[i, 3:(ncol(taxres_df))] <-
c(ltg, pidl, pcovl, phitl, taxnl, seqnl, refresl, ltgresl)
class(taxres)
class(taxres_df)
# fill out line with the ltg and the parmeters that were used to get it
taxres_df[i, 3:(ncol(taxres_df))] <-
list(ltg, pidl, pcovl, phitl, taxnl, seqnl, refresl, ltgresl)
View(taxres_df)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
out_tax <- file.path(outdir, "taxonomy.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE)
View(asv_tax)
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
quiet=FALSE,
outfile = out_tax)
load_all(".")
roxygenise()
usethis::use_roxygen_md()
out_tax <- file.path(outdir, "taxonomy.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
outfile = out_tax)
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
outfile = out_tax)
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads,
outfile = out_tax)
View(asv_tax)
### If pb with vignette not building correctly
# clean package
unlink("~/R/x86_64-pc-linux-gnu-library/4.0/vtamR", recursive = TRUE, force = TRUE)
file.exists("~/R/x86_64-pc-linux-gnu-library/4.0/vtamR")
# Clean and regenerate documentation:
devtools::clean_dll()
devtools::document()
devtools::install(build_vignettes = FALSE, force = TRUE)
# test library
library(vtamR)
# install with vignettes (local)
devtools::install(build_vignettes = TRUE)
### If pb with vignette not building correctly
# clean package
unlink("~/R/x86_64-pc-linux-gnu-library/4.0/vtamR", recursive = TRUE, force = TRUE)
file.exists("~/R/x86_64-pc-linux-gnu-library/4.0/vtamR")
# Clean and regenerate documentation:
devtools::clean_dll()
devtools::document()
### If pb with vignette not building correctly
# clean package
unlink("~/R/x86_64-pc-linux-gnu-library/4.0/vtamR", recursive = TRUE, force = TRUE)
file.exists("~/R/x86_64-pc-linux-gnu-library/4.0/vtamR")
# Clean and regenerate documentation:
devtools::clean_dll()
devtools::document()
devtools::install(build_vignettes = FALSE, force = TRUE)
# install with vignettes (local)
devtools::install(build_vignettes = TRUE)
vignette(package = "vtamR")
vignette("installation")
# build tarball with vignettes
devtools::build(vignettes = TRUE)
