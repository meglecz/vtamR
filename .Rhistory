packageVersion("dada2")
path <-  "/home/meglecz/vtam_data/dada2/1_input_vtam-0.1.12/MFZR_orientation_pooled"
list.files(path)
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_fw.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_rv.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnFs[3:8])
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
# quality filter
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(160,160),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
library(dplyr)
orig <- read.table("/home/meglecz/vtam_git/16S/16S_asvtable_TAS1-2_read_counts.tsv", sep="\t", header=TRUE)
orig <- read.table("/home/meglecz/vtam_git/16S/16S_asvtable_TAS1-2_read_counts.tsv", sep="\t", header=TRUE, na.strings = "")
orig <- read.table("/home/meglecz/vtam_git/16S/16S_asvtable_TAS1-2_read_counts.tsv", sep="\t", header=TRUE, na.strings = "", fill=TRUE)
View(orig)
caunt <- read.table("/home/meglecz/vtam_git/16S/SuppMat_16S_WO_tax.csv", sep="\t", header=TRUE, na.strings = "", fill=TRUE)
count <- read.table("/home/meglecz/vtam_git/16S/SuppMat_16S_WO_tax.csv", sep="\t", header=TRUE, na.strings = "", fill=TRUE)
colnames(orig)
orig <- orig %>%
select(1, 152:163)
colnames(orig) <- c("domain", "domain_bootstrap", "phylum", "phylum_bootstrap", "class", "class_bootstrap", "order", "order_bootstrap", "family", "family_bootstrap", "genus", "genus_bootstrap")
colnames(orig) <- c("variant_id", "domain", "domain_bootstrap", "phylum", "phylum_bootstrap", "class", "class_bootstrap", "order", "order_bootstrap", "family", "family_bootstrap", "genus", "genus_bootstrap")
colnames(count)
count <- left_join(count, orig, by="variant_id")
colnames(count)
write.csv2(file="/home/meglecz/vtam_git/16S/SuppMat_VTAM16S_corrected.tsv", count)
write.table(count, file="/home/meglecz/vtam_git/16S/SuppMat_VTAM16S_corrected.tsv", count=FALSE, sep=";", dec=".", row.names=FALSE)
write.table(count, file="/home/meglecz/vtam_git/16S/SuppMat_VTAM16S_corrected.tsv", quote=FALSE, sep=";", dec=".", row.names=FALSE)
bold <- read.table(tsv, sep="\t", header=TRUE, fill=TRUE)
tsv <- "/home/meglecz/mkCOInr/BOLD_2025_02/BOLD_Public.21-Feb-2025.tsv"
bold <- read.table(tsv, sep="\t", header=TRUE, fill=TRUE)
bold <- read.table(tsv, sep="\t", header=TRUE, fill=TRUE)
library(vtamR)
# Linux
cutadapt_path <- "~/miniconda3/envs/vtam/bin/cutadapt" # v3.4
vsearch_path <- "~/miniconda3/envs/vtam/bin/vsearch" # v2.15.1
blast_path <- "~/miniconda3/envs/vtam/bin/blastn" # v2.10.1+
swarm_path <- "swarm" # v2.1.12
num_threads <- 8
sep <- ","
taxonomy <- "COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam"
fastq_dir <- system.file("extdata/demo/fastq", package = "vtamR")
outdir <- "~/vtamR_demo/out_mfzr"
fastqinfo <-  system.file("extdata/demo/fastqinfo_mfzr.csv", package = "vtamR")
mock_composition <-  system.file("extdata/demo/mock_composition_mfzr.csv", package = "vtamR")
asv_list <-  system.file("extdata/demo/asv_list.csv", package = "vtamR")
fastq_dir <- system.file("extdata/demo/fastq", package = "vtamR")
outdir <- "~/vtamR_demo/out_mfzr"
fastqinfo <-  system.file("extdata/demo/fastqinfo_mfzr.csv", package = "vtamR")
mock_composition <-  system.file("extdata/demo/mock_composition_mfzr.csv", package = "vtamR")
asv_list <-  system.file("extdata/demo/asv_list.csv", package = "vtamR")
CheckFileinfo(file=fastqinfo, dir=fastq_dir, file_type="fastqinfo")
CheckFileinfo(file=mock_composition, file_type="mock_composition")
CheckFileinfo(file=asv_list, file_type="asv_list")
# merge and quality filter
merged_dir <- file.path(outdir, "merged")
fastainfo_df <- Merge(fastqinfo,
fastq_dir=fastq_dir,
vsearch_path=vsearch_path,
outdir=merged_dir
)
# demultiplex, trim tags and pimers
sorted_dir <- file.path(outdir, "sorted")
sortedinfo_df <- SortReads(fastainfo_df,
fasta_dir=merged_dir,
outdir=sorted_dir,
check_reverse=TRUE,
cutadapt_path=cutadapt_path,
vsearch_path=vsearch_path
)
outdir
outfile <- file.path(outdir, "1_before_filter.csv")
outfile <- file.path(outdir, "1_before_filter.csv")
updated_asv_list <- file.path(outdir, "ASV_list_with_IDs.csv")
read_count_df <- Dereplicate(sortedinfo_df,
dir=sorted_dir,
outfile=outfile,
asv_list=asv_list,
updated_asv_list=updated_asv_list
)
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
stat_df <- GetStat(read_count_df, stat_df, stage="Input", params=NA)
by_sample <- TRUE
outfile <- file.path(outdir, "2_Swarm_by_sample.csv")
read_count_df <- Swarm(read_count_df,
outfile=outfile,
swarm_path=swarm_path,
num_threads=num_threads,
by_sample=by_sample
)
stat_df <- GetStat(read_count_df, stat_df, stage="Swarm", params=by_sample)
print(stat_df)
print(stat_df)
Histogram_ReadCountByVariant(read_count_df, min_read_count=10, binwidth=100)
Although, swarm has reduced considerably the number of ASVs, there are still
many ASVs with low read count.
The `LFNglobalReadCount` function filter out all ASVs with total read count
bellow a threshold.
global_read_count_cutoff = 2
outfile <- file.path(outdir, "3_LFNglobalReadCount.csv")
read_count_df <- LFNglobalReadCount(read_count_df,
cutoff=global_read_count_cutoff,
outfile=outfile
)
stat_df <- GetStat(read_count_df,
stat_df,
stage="LFNglobalReadCount",
params=global_read_count_cutoff
)
print(stat_df)
outfile <- file.path(outdir, "4_FilterIndel.csv")
read_count_df <- FilterIndel(read_count_df, outfile=outfile)
stat_df <- GetStat(read_count_df, stat_df, stage="FilterIndel")
print(stat_df)
outfile <- file.path(outdir, "5_FilterCodonStop.csv")
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, outfile=outfile, genetic_code=genetic_code)
stat_df <- GetStat(read_count_df, stat_df, stage="FilerCodonStop", params=genetic_code)
print(stat_df)
abskew=2
by_sample = T
sample_prop = 0.8
outfile <- file.path(outdir, "6_FilterChimera.csv")
read_count_df <- FilterChimera(read_count_df, outfile=outfile, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew)
params <- paste(abskew, by_sample, sample_prop, sep=";")
stat_df <- GetStat(read_count_df, stat_df, stage="FilterChimera", params=params)
print(stat_df)
renkonen_within_df <- MakeRenkonenDistances(read_count_df, compare_all=FALSE)
renkonen_density_plot <- DensityPlot_RenkonenDistance(renkonen_within_df)
print(renkonen_density_plot)
DensityPlot_RenkonenDistance(renkonen_within_df)
?Barplot_RenkonenDistance
sorted_dir
Barplot_RenkonenDistance(renkonen_within_df, sample_types=sortedinfo_df, x_axis_label_size=6)
# Load package without installing; Use during development
devtools::load_all()
Barplot_RenkonenDistance(renkonen_within_df, sample_types=sortedinfo_df, x_axis_label_size=6)
View(sortedinfo_df)
# Load package without installing; Use during development
devtools::load_all()
Barplot_RenkonenDistance(renkonen_within_df, sample_types=sortedinfo_df, x_axis_label_size=6)
# Load package without installing; Use during development
devtools::load_all()
Barplot_RenkonenDistance(renkonen_within_df, sample_types=sortedinfo_df, x_axis_label_size=6)
outfile <- file.path(outdir, "7_FilterRenkonen.csv")
cutoff <- 0.4
read_count_df <- FilterRenkonen(read_count_df, outfile=outfile, cutoff=cutoff)
stat_df <- GetStat(read_count_df, stat_df, stage="FilerRenkonen", params=cutoff)
print(stat_df)
outfile <- file.path(outdir, "OptimizePCRerror.csv")
OptimizePCRerror_df <- OptimizePCRerror(read_count_df,
mock_composition=mock_composition,
vsearch_path=vsearch_path,
outfile=outfile,
max_mismatch=2,
min_read_count=5
)
pcr_error_var_prop <- 0.05
max_mismatch <- 2
outfile <- file.path(outdir, "8_FilterPCRerror.csv")
read_count_df <- FilterPCRerror(read_count_df,
outfile=outfile,
vsearch_path=vsearch_path,
pcr_error_var_prop=pcr_error_var_prop,
max_mismatch=max_mismatch
)
params <- paste(pcr_error_var_prop, max_mismatch, by_sample, sep=";")
stat_df <- GetStat(read_count_df, stat_df, stage="FilterPCRerror", params=params)
print(stat_df)
outfile = file.path(outdir, "OptimizeLFNsampleReplicate.csv")
OptimizeLFNsampleReplicate_df <- OptimizeLFNsampleReplicate(read_count=read_count_df,
mock_composition=mock_composition,
outfile=outfile)
head(OptimizeLFNsampleReplicate_df)
lfn_sample_replicate_cutoff <- 0.004
outfile <- file.path(outdir, "9_LFNsampleReplicate.csv")
read_count_df <- LFNsampleReplicate(read_count_df,
cutoff=lfn_sample_replicate_cutoff,
outfile=outfile
)
stat_df <- GetStat(read_count_df,
stat_df,
stage="LFNsampleReplicate",
params=lfn_sample_replicate_cutoff
)
print(stat_df)
min_replicate_number <- 2
outfile <- file.path(outdir, "10_FilterMinReplicate.csv")
read_count_df <- FilterMinReplicate(read_count_df,
min_replicate_number,
outfile=outfile
)
stat_df <- GetStat(read_count_df,
stat_df,
stage="FilterMinReplicate",
params=min_replicate_number
)
print(stat_df)
# Pool replicates
read_count_samples_df <- PoolReplicates(read_count_df)
# Detect known occurrences
results <- MakeKnownOccurrences(read_count_samples = read_count_samples_df,
sortedinfo=sortedinfo,
mock_composition=mock_composition
)
?MakeKnownOccurrences
# Pool replicates
read_count_samples_df <- PoolReplicates(read_count_df)
# Detect known occurrences
results <- MakeKnownOccurrences(read_count_samples = read_count_samples_df,
sortedinfo=sortedinfo_df,
mock_composition=mock_composition
)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
outfile = file.path(outdir, "OptimizeLFNreadCountLFNvariant.csv")
OptimizeLFNreadCountLFNvariant_df <- OptimizeLFNreadCountLFNvariant(
read_count_df,
known_occurrences=known_occurrences_df,
outfile= outfile,
min_replicate_number=2
)
OptimizeLFNreadCountLFNvariant_df <- OptimizeLFNreadCountLFNvariant(
read_count_df,
known_occurrences=known_occurrences_df,
outfile= outfile,
min_replicate_number=2
)
head(OptimizeLFNreadCountLFNvariant_df)
lnf_variant_cutoff = 0.001
outfile <- file.path(outdir, "11_LFNvariant.csv")
read_count_df_lnf_variant <- LFNvariant(read_count_df,
cutoff=lnf_variant_cutoff,
outfile=outfile
)
stat_df <- GetStat(read_count_df_lnf_variant,
stat_df,
stage="LFNvariant",
params=lnf_variant_cutoff)
lfn_read_count_cutoff <- 10
outfile <- file.path(outdir, "12_LFNreadCount.csv")
read_count_df_lfn_read_count <- LFNreadCount(read_count_df,
cutoff=lfn_read_count_cutoff,
outfile=outfile
)
stat_df <- GetStat(read_count_df_lfn_read_count,
stat_df, stage="LFNreadCount",
params=lfn_read_count_cutoff
)
outfile <- file.path(outdir, "13_poolLFN.csv")
read_count_df <- PoolFilters(read_count_df_lfn_read_count,
read_count_df_lnf_variant,
outfile=outfile
)
stat_df <- GetStat(read_count_df,
stat_df,
stage="FilterLFN"
)
# delete temporary data frames
rm(read_count_df_lfn_read_count)
rm(read_count_df_lnf_variant)
print(stat_df)
min_replicate_number <- 2
outfile <- file.path(outdir, "14_FilterMinReplicate.csv")
read_count_df <- FilterMinReplicate(read_count_df,
min_replicate_number,
outfile=outfile
)
stat_df <- GetStat(read_count_df,
stat_df,
stage="FilterMinReplicate",
params=min_replicate_number
)
print(stat_df)
outfile <- file.path(outdir, "15_PoolReplicates.csv")
read_count_samples_df <- PoolReplicates(read_count_df,
outfile=outfile
)
stat_df <- GetStat(read_count_samples_df,
stat_df,
stage="PoolReplicates"
)
print(stat_df)
missing_occurrences <- file.path(outdir, "missing_occurrences.csv")
performance_metrics <- file.path(outdir, "performance_metrics.csv")
known_occurrences <- file.path(outdir, "known_occurrences.csv")
results <- MakeKnownOccurrences(read_count_samples_df,
sortedinfo=sortedinfo_df,
mock_composition=mock_composition,
known_occurrences=known_occurrences,
missing_occurrences=missing_occurrences,
performance_metrics=performance_metrics
)
# give explicit names to the 3 output data frames
known_occurrences_df <- results[[1]]
missing_occurrences_df <- results[[2]]
performance_metrics_df <- results[[3]]
outfile <- file.path(outdir, "TaxAssign.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
getwd()
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
taxonomy <- "COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam"
outfile <- file.path(outdir, "TaxAssign.csv")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
taxonomy
getwd()
# Load package without installing; Use during development
devtools::load_all()
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
path.expand(taxonomy)
taxonomy <- "~/COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam_taxonomy.tsv"
blast_db <- "~/COInr_for_vtam_2025_05_23_dbV5/COInr_for_vtam"
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
outfile=file.path(outdir, "Final_asvtable_with_TaxAssign.csv")
asv_table_df <- WriteASVtable(read_count_samples_df,
outfile=outfile,
asv_tax=asv_tax,
sortedinfo=sortedinfo_df,
add_empty_samples=T,
add_sums_by_sample=T,
add_sums_by_asv=T,
add_expected_asv=T,
mock_composition=mock_composition
)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
save(asv_tax, file = "~/vtamR/inst/exdata/demo/asv_tax.rda")
save(asv_tax, file = "inst/exdata/demo/asv_tax.rda")
save(asv_tax, file = "inst/extdata/demo/asv_tax.rda")
save(asv_tax, file = "/home/meglecz/vtamR/inst/extdata/demo/asv_tax.rda")
original_asv_taxa <- load("my_data.rda")
original_asv_taxa <- load("asv_tax.rda")
load("asv_tax.rda")
full_asv_tax <- asv_taxa
full_asv_tax <- asv_tax
usethis::use_data(full_asv_tax, overwrite = TRUE)
rm(full_asv_tax)
data(full_asv_tax)
taxonomy <- "/home/meglecz/vtamR/vtamR_test/test/db_test/taxonomy_reduced.tsv"
blast_db <- "/home/meglecz/vtamR/vtamR_test/test/db_test/COInr_reduced"
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
View(asv_tax)
View(full_asv_tax)
View(full_asv_tax)
taxonomy <- system.file("extdata/db_test/taxonomy_reduced.tsv", package = "vtamR")
blast_db <- system.file("extdata/db_test/COInr_reduced", package = "vtamR")
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
taxonomy <- system.file("extdata/db_test/taxonomy_reduced.tsv", package = "vtamR")
blast_db <- system.file("extdata/db_test/COInr_reduced", package = "vtamR")
taxonomy
blast_db
fastq_dir <- system.file("extdata/demo/fastq", package = "vtamR")
fastq_dir
blast_db <- system.file("extdata/db_test/COInr_reduced", package = "vtamR")
blast_db <- system.file("extdata/db_test", package = "vtamR")
file.path(blast_db, "COInr_reduced")
blast_db <- file.path(blast_db, "COInr_reduced")
taxonomy <- system.file("extdata/db_test/taxonomy_reduced.tsv", package = "vtamR")
blast_db <- system.file("extdata/db_test", package = "vtamR")
blast_db <- file.path(blast_db, "COInr_reduced")
blast_db
taxonomy
asv_tax <- TaxAssign(asv=read_count_samples_df,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
outfile=outfile,
num_threads=num_threads
)
View(asv_tax)
# Run checks before releasing a package
devtools::check()
# Adapt tutorial_vtamR.Rmd to vignette
# To Build, Code must execute or use eval=FALSE;
# Build execute vtam.Rmd to R and html to doc dir
# and creates a copy of vtamR.Rmd to doc as well.
# It the vignette needs to be edited, the file in
# vignettes/ should be edited and built again.
devtools::build_vignettes()
# view a vignette
vignette("installation")
vignette("tutorial-vtamr-pipeline")
# list vignettes
vignette(package = "vtamR")
### to test as a package
# Install the package
devtools::install()
vtamR
library(vtamR)
?Merge
?Merge
devtools::install()
getwd()
setwd(~/vtamR)
setwd("~/vtamR")
devtools::install()
system.file("extdata/db_test", package = "vtamR")
list.files(system.file("extdata/db_test", package = "vtamR"))
library(vtamR)
library(dplyr)
read_count_file <- system.file("extdata/demo/7_FilterRenkonen.csv", package = "vtamR")
taxonomy <- system.file("extdata/db_test/taxonomy_reduced.tsv", package = "vtamR")
blast_db <- system.file("extdata/db_test", package = "vtamR")
blast_db <- file.path(blast_db, "COInr_reduced")
blast_path <- "~/miniconda3/envs/vtam/bin/blastn"
num_threads = 8
asv_tax <- TaxAssign(asv=read_count_file,
taxonomy=taxonomy,
blast_db=blast_db,
blast_path=blast_path,
num_threads=num_threads
)
read_count_samples_df <- PoolReplicates(read_count_file)
outdir <- "~/vtamR_demo/out_mfzr"
sortedinfo <- system.file("extdata/demo/sortedinfo.csv", package = "vtamR")
tmp_asv_table <- WriteASVtable(read_count_samples_df,
sortedinfo=sortedinfo,
add_sums_by_asv=T,
asv_tax=asv_tax)
asv_tpos1 <- tmp_asv_table %>%
select(tpos1, Total_number_of_reads, Number_of_samples, asv_id,
phylum, class, order, family, genus, species, asv
) %>%
filter(tpos1 > 0) %>%
arrange(desc(tpos1))
View(asv_tpos1)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
# Adapt tutorial_vtamR.Rmd to vignette
# To Build, Code must execute or use eval=FALSE;
# Build execute vtam.Rmd to R and html to doc dir
# and creates a copy of vtamR.Rmd to doc as well.
# It the vignette needs to be edited, the file in
# vignettes/ should be edited and built again.
devtools::build_vignettes()
# view a vignette
vignette("installation")
### to test as a package
# Install the package
devtools::install()
# view a vignette
vignette("installation")
# list vignettes
vignette(package = "vtamR")
### to test as a package
# Install the package
devtools::install(build_vignettes = TRUE)
# view a vignette
vignette("installation")
vignette("make-mock-composition-file")
vignette("tutorial-vtamr-pipeline")
# list vignettes
vignette(package = "vtamR")
devtools::build(vignettes = TRUE)
getwd()
