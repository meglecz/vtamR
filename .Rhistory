outdir <- check_dir(outdir)
outfile <- paste(outdir, "out_taxassign.csv", sep="")
input_df <- read.csv(input)
input
test_dir="vtamR_test/"
test_dir <- check_dir(test_dir)
input <- paste(test_dir, "test/input_taxassign.csv", sep="")
expeted_output <- paste(test_dir, "test/test_taxassign_out.tsv", sep="")
outdir <- paste(test_dir, "out/taxassign/", sep="")
outdir <- check_dir(outdir)
outfile <- paste(outdir, "out_taxassign.csv", sep="")
input_df <- read.csv(input)
input_df <- input_df %>%
select(asv=sequence)
asv_tax <- TaxAssign(df=input_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outdir=outdir, num_threads=num_threads)
expected_asv_tax <- read.table(expeted_output, sep="\t", header=T)
expected_asv_tax <- expected_asv_tax %>%
select(pid_exp=pid,ltg_taxid_exp=ltg_taxid, ltg_name_exp=ltg_name, ltg_rank_exp=ltg_rank, superkingdom_exp=superkingdom, kingdom_exp=kingdom, phylum_exp=phylum, class_exp=class, order_exp=order, family_exp=family, genus_exp=genus, species_exp=species, asv=sequence)
tmp_NA <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(is.na(ltg_taxid))
tmp_OK <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid==ltg_taxid_exp)
tmp_KO <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid!=ltg_taxid_exp)
View(tmp_KO)
View(tmp_NA)
View(tmp_OK)
View(tmp_NA)
df <- input_df
outdir<- "vtamR_test/taxassign/"
outdir <- check_dir(outdir)
#### Read taxonomy info
# read taxonomy file; quote="" is important, since some of the taxon names have quotes and this should be ignored
tax_df <- read.delim(taxonomy, header=T, sep="\t", fill=T, quote="")
# make data frame with old taxids as line numbers and taxids in a columns
old_taxid <- tax_df %>%
filter(!is.na(old_tax_id)) %>%
select(tax_id, old_tax_id)
# delete old_tax_ids from tax_df and make taxids unique
tax_df <- tax_df %>%
select(-old_tax_id)
tax_df <- unique(tax_df)
####
# create a tmp directory for temporary files using time and a random number
outdir_tmp <- paste(outdir, 'tmp_', trunc(as.numeric(Sys.time())), sample(1:100, 1), sep='')
outdir_tmp <- check_dir(outdir_tmp)
### run blast and clean/complete results
# run blast and read results to data frame (blast_res columns: "qseqid","pident","qcovhsp","staxids")
blast_res <- run_blast(df, blast_db=blast_db, blast_path=blast_path, outdir=outdir_tmp, qcov_hsp_perc=min(ltg_params_df$pcov), perc_identity=min(ltg_params_df$pid), num_threads=num_threads)
# add update old taxids to valid ones
blast_res <- update_taxids(blast_res, old_taxid)
# add taxlevel
blast_res <- left_join(blast_res, tax_df, by=c("staxids" = "tax_id")) %>%
select(-parent_tax_id, -rank, -name_txt)
### make a lineage for each taxid in blastres
lineages <- get_lineage_ids(unique(blast_res$staxids), tax_df)
# initialize data frame with asv and NA for all other cells
taxres_df <- data.frame(asv = unique(df$asv), ltg_taxid = NA, pid=NA, pcov=NA, phit=NA, taxn=NA, seqn=NA, refres=NA, ltgres=NA)
View(taxres_df)
i=39
View(tmp_NA)
View(old_taxid)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
View(ltg_params_df)
i=39
p=6
#      p=6
pidl <- ltg_params_df[p,"pid"]
pcovl <- ltg_params_df[p,"pcov"]
phitl <- ltg_params_df[p,"phit"]
taxnl <- ltg_params_df[p,"taxn"]
seqnl <- ltg_params_df[p,"seqn"]
refresl <- ltg_params_df[p,"refres"]
ltgresl <- ltg_params_df[p,"ltgres"]
pidl
# filter the blastres according to  pid, pcov, refres
df_intern <- blast_res %>%
filter(qseqid==i & pident>=pidl & qcovhsp>=pcovl & taxlevel>=refresl)
View(df_intern)
# check if enough taxa and seq among validated hits
tn <- length(unique(df_intern$staxids))
tn >= taxnl
tn
df_intern$staxids
taxids = df_intern$staxids
lin <- as.data.frame(taxids)
colnames(lin) <- c("staxid")
# add lineage to each taxid
lin <- left_join(lin, lineages, by=c("staxid" = "taxids")) %>%
select(-where(~all(is.na(.)))) # delete columns if all elements are NA
View(lin)
ltg <- NA
for(i in 2:ncol(lin)){ # start from low resolution
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
if(max_hitn/sum(tmp[,"nhit"]) < phit/100){
break
}
ltg <- as.numeric(tmp[1,"tax_id"])
}
phit=70
for(i in 2:ncol(lin)){ # start from low resolution
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
if(max_hitn/sum(tmp[,"nhit"]) < phit/100){
break
}
ltg <- as.numeric(tmp[1,"tax_id"])
}
ltg
View(tmp_NA)
i=8
tmp <- as.data.frame(lin[,i])
View(tmp)
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=9
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=10
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
i=11
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
i=12
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=13
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
i=14
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=15
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=16
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
i=15
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=16
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=17
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=18
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
i=18
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
# if the taxid with the highest number of sequences does not contain at least phit percent of the hits, stop
max_hitn <- as.numeric(tmp[1,"nhit"])
max_hitn
max_hitn/sum(tmp[,"nhit"])
ltg <- as.numeric(tmp[1,"tax_id"])
ltg
i=19
tmp <- as.data.frame(lin[,i])
colnames(tmp) <- c("tax_id")
# get unique taxids, and their numbers in the i-th column
tmp <- tmp %>%
group_by(tax_id) %>%
summarize(nhit=length(tax_id)) %>%
arrange(desc(nhit))
computer <- "Windows" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
#  fastqdir <- "/home/meglecz/vtamR_large_files/fastq/"
#  fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#  outdir <- "/home/meglecz/vtamR_large_files/out/"
mock_composition <- "local/user_input/mock_composition_mfzr_eu.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "local/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=4
compress = F
}
sep=";"
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
test_dir <- check_dir(test_dir)
test_dir="vtamR_test/"
test_dir <- check_dir(test_dir)
input <- paste(test_dir, "test/input_taxassign.csv", sep="")
expeted_output <- paste(test_dir, "test/test_taxassign_out.tsv", sep="")
outdir <- paste(test_dir, "out/taxassign/", sep="")
outdir <- check_dir(outdir)
outfile <- paste(outdir, "out_taxassign.csv", sep="")
input_df <- read.csv(input)
input_df <- input_df %>%
select(asv=sequence)
asv_tax <- TaxAssign(df=input_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outdir=outdir, num_threads=num_threads)
expected_asv_tax <- read.table(expeted_output, sep="\t", header=T)
expected_asv_tax <- read.table(expeted_output, sep="\t", header=T)
expected_asv_tax <- expected_asv_tax %>%
select(pid_exp=pid,ltg_taxid_exp=ltg_taxid, ltg_name_exp=ltg_name, ltg_rank_exp=ltg_rank, superkingdom_exp=superkingdom, kingdom_exp=kingdom, phylum_exp=phylum, class_exp=class, order_exp=order, family_exp=family, genus_exp=genus, species_exp=species, asv=sequence)
tmp_NA <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(is.na(ltg_taxid))
tmp_OK <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid==ltg_taxid_exp)
tmp_KO <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid!=ltg_taxid_exp)
View(tmp_KO)
View(tmp_NA)
View(tmp_OK)
asv_taxassign <- left_join(asv_tax, expected_asv_tax, by="asv")
View(asv_taxassign)
tmp_OK <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid==ltg_taxid_exp)
View(tmp_OK)
asv_taxassign$ltg_taxid[is.na(asv_taxassign$ltg_taxid)] <- 0
View(asv_taxassign)
asv_taxassign$ltg_taxid_exp[is.na(asv_taxassign$ltg_taxid_exp)] <- 0
View(asv_taxassign)
tmp_KO <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid!=ltg_taxid_exp)
View(tmp_KO)
tmp_OK <- left_join(asv_tax, expected_asv_tax, by="asv") %>%
filter(ltg_taxid==ltg_taxid_exp)
View(tmp_OK)
tmp_NA <- asv_taxassign %>%
filter(is.na(ltg_taxid) & is.na(ltg_taxid_exp))
tmp_OK <- asv_taxassign %>%
filter(ltg_taxid==ltg_taxid_exp)
tmp_KO <- asv_taxassign %>%
filter(ltg_taxid!=ltg_taxid_exp)
View(tmp_NA)
View(tmp_OK)
View(tmp_KO)
test_taxassign <- function(test_dir="~/vtamR/vtamR_test/", sep=sep, blast_path=blast_path, blast_db=blast_db, taxonomy=taxonomy){
test_dir <- check_dir(test_dir)
input <- paste(test_dir, "test/input_taxassign.csv", sep="")
expeted_output <- paste(test_dir, "test/test_taxassign_out.tsv", sep="")
outdir <- paste(test_dir, "out/taxassign/", sep="")
outdir <- check_dir(outdir)
outfile <- paste(outdir, "out_taxassign.csv", sep="")
input_df <- read.csv(input)
input_df <- input_df %>%
select(asv=sequence)
asv_tax <- TaxAssign(df=input_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outdir=outdir, num_threads=num_threads)
expected_asv_tax <- read.table(expeted_output, sep="\t", header=T)
expected_asv_tax <- expected_asv_tax %>%
select(pid_exp=pid,ltg_taxid_exp=ltg_taxid, ltg_name_exp=ltg_name, ltg_rank_exp=ltg_rank, superkingdom_exp=superkingdom, kingdom_exp=kingdom, phylum_exp=phylum, class_exp=class, order_exp=order, family_exp=family, genus_exp=genus, species_exp=species, asv=sequence)
asv_taxassign <- left_join(asv_tax, expected_asv_tax, by="asv")
asv_taxassign$ltg_taxid[is.na(asv_taxassign$ltg_taxid)] <- 0
asv_taxassign$ltg_taxid_exp[is.na(asv_taxassign$ltg_taxid_exp)] <- 0
tmp_KO <- asv_taxassign %>%
filter(ltg_taxid!=ltg_taxid_exp)
if(nrow(tmp_KO)==0){
cat("Taxxassign: PASS")
}else{
cat("Taxxassign: FAIL")
}
return(asv_taxassign)
}
test_taxassign(test_dir="vtamR_test/", sep=sep, blast_path=blast_path, blast_db=blast_db, taxonomy=taxonomy)
computer <- "Windows" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
#  fastqdir <- "/home/meglecz/vtamR_large_files/fastq/"
#  fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#  outdir <- "/home/meglecz/vtamR_large_files/out/"
mock_composition <- "local/user_input/mock_composition_mfzr_eu.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "local/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=4
compress = F
}
sep=";"
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge, SortReads and filter
###
test_merge_and_sortreads(test_dir="vtamR_test/", vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
test_taxassign <- function(test_dir="~/vtamR/vtamR_test/", sep=sep, blast_path=blast_path, blast_db=blast_db, taxonomy=taxonomy){
test_dir <- check_dir(test_dir)
input <- paste(test_dir, "test/input_taxassign.csv", sep="")
expeted_output <- paste(test_dir, "test/test_taxassign_out.tsv", sep="")
outdir <- paste(test_dir, "out/taxassign/", sep="")
outdir <- check_dir(outdir)
outfile <- paste(outdir, "out_taxassign.csv", sep="")
input_df <- read.csv(input)
input_df <- input_df %>%
select(asv=sequence)
asv_tax <- TaxAssign(df=input_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outdir=outdir, num_threads=num_threads)
expected_asv_tax <- read.table(expeted_output, sep="\t", header=T)
expected_asv_tax <- expected_asv_tax %>%
select(pid_exp=pid,ltg_taxid_exp=ltg_taxid, ltg_name_exp=ltg_name, ltg_rank_exp=ltg_rank, superkingdom_exp=superkingdom, kingdom_exp=kingdom, phylum_exp=phylum, class_exp=class, order_exp=order, family_exp=family, genus_exp=genus, species_exp=species, asv=sequence)
asv_taxassign <- left_join(asv_tax, expected_asv_tax, by="asv")
asv_taxassign$ltg_taxid[is.na(asv_taxassign$ltg_taxid)] <- 0
asv_taxassign$ltg_taxid_exp[is.na(asv_taxassign$ltg_taxid_exp)] <- 0
tmp_KO <- asv_taxassign %>%
filter(ltg_taxid!=ltg_taxid_exp)
if(nrow(tmp_KO)==0){
cat("Taxxassign: PASS")
}else{
cat("Taxxassign: FAIL")
}
return(asv_taxassign)
}
test_filters(test_dir="vtamR_test/", vsearch_path=vsearch_path, sep=sep)
test_make_known_occurrences(test_dir="vtamR_test/", sep=sep)
start_time <- Sys.time()  # Record the start time
taxassign_comaraison <- test_taxassign(test_dir="vtamR_test/", sep=sep, blast_path=blast_path, blast_db=blast_db, taxonomy=taxonomy)
end_time <- Sys.time()  # Record the end time
runtime <- end_time - start_time  # Calculate the run time
print(runtime)
