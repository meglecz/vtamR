load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files
# create the output directory and check the the slash at the end
outdir <- check_dir(dir=outdir)
fastqdir <- check_dir(dir=fastqdir)
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
###
### Merge
###
fastq_ascii <- 33
fastq_maxdiffs <- 10
fastq_maxee <- 1
fastq_minlen <- 50
fastq_maxlen <- 500
fastq_minmergelen <- 50
fastq_maxmergelen <-500
fastq_maxns <- 0
fastq_truncqual <- 10
fastq_minovlen <- 50
fastq_allowmergestagger <- F
merged_dir <- paste(outdir, "merged/", sep="")
compress = T
# read fastqinfo
fastqinfo_df <- read.csv(fastqinfo, header=T, sep=sep)
fastainfo <- paste(merged_dir, "fastainfo_gz.csv", sep="")
fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
merged_dir <- paste(outdir, "merged/", sep="")
fastainfo <- paste(merged_dir, "fastainfo_gz.csv", sep="")
fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
fastainfo
fastainfo <- paste(merged_dir, "fastainfo.csv", sep="")
fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
compress = T
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
###
### RandomSeq
###
randomseq_dir = paste(outdir, "random_seq/", sep="")
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
#'
#' @param fastainfo_df data frame with a 'fasta' column containing input file names; files can be compressed in gz and zip format
#' @param n integer; the number of randomly selected sequences
#' @param fasta_dir directory that contains the input fasta files
#' @param outdir directory for the output files
#' @param vsearch_path path to vsearch
#' @param randseed positive integer; seed for random sampling; 0 by default means to use a pseudo-random seed, a given non-zero seed produce always the same result
#' @param compress [T/F]; If TRUE, output files are compressed in the same format as the input. Otherwise the output is uncompressed;
#' @export
#'
RandomSeq <- function(fastainfo_df, fasta_dir="", outdir="", vsearch_path="", n, randseed=0, compress=F){
# quite fast for uncompressed and gz files
fasta_dir<- check_dir(fasta_dir)
vsearch_path<- check_dir(vsearch_path)
outdir<- check_dir(outdir)
fastainfo_df$new_file <- NA
fastainfo_df$read_count <- NA
unique_fasta <- unique(fastainfo_df$fasta)
for(i in 1:length(unique_fasta)){ # go through all fasta files
input_fasta <- unique_fasta[i]
# adjust output filename in function of the compression
output_fasta <- input_fasta
if(compress && !endsWith(output_fasta, ".gz")){
output_fasta <- paste(output_fasta, ".gz", sep="")
}
if(!compress && endsWith(output_fasta, ".gz")){
output_fasta <- sub(".gz$", "", output_fasta)
}
if(endsWith(input_fasta, ".zip")){
stop("Zip files are not supported")
}
original_input_fasta_p <- paste(fasta_dir, input_fasta, sep="")
input_fasta_p <- paste(fasta_dir, input_fasta, sep="") # name can change if file de/recompressed
if(!is_linux() && endsWith(original_input_fasta_p, ".gz")){ #Decompress input files, since they are cannot be treated directly by vsearch on the OS
input_fasta_p <- decompress_file(input_fasta_p, remove_input=F)
}
output_fasta_p <- paste(outdir, input_fasta, sep="")
seq_n <- count_seq(file=input_fasta_p)
if(n > seq_n ){ # not enough seq
file.copy(original_input_fasta_p, output_fasta_p)
msg <- paste("WARNING:", input_fasta_p,"has",seq_n,"sequences, which is lower than", n,". The file is copied to the",outdir,"directory without subsampling", sep=" ")
print(msg)
# the original file has been decompressed  => remove the decompressed file
if(input_fasta_p != original_input_fasta_p){
file.remove(input_fasta_p)
}
# the outfile is not yet compressed
if(compress && !endsWith(output_fasta_p, ".gz")){
output_fasta_p <- compress_file(filename=output_fasta_p, remove_input=T)
}
fastainfo_df$new_file[which(fastainfo_df$fasta==input_fasta)] <- output_fasta
fastainfo_df$read_count[which(fastainfo_df$fasta==input_fasta)] <- seq_n
next()
}
# enough seq => resample
options(scipen=100) # do not transform large numbers to scentific forms, since it would lead to an error in vsearch
output_fasta_p <- gsub(".gz", "", output_fasta_p) # vsearch makes decompressed files
vsearch_cmd <- paste(vsearch_path, "vsearch --fastx_subsample ", input_fasta_p, " --fastaout ", output_fasta_p, " --sample_size ", n, " --randseed ", randseed, sep="")
print(vsearch_cmd)
system(vsearch_cmd)
options(scipen=0)
if(compress){ # compress the output file
output_fasta_p <- compress_file(filename=output_fasta_p, remove_input=T)
}
if(!is_linux() && endsWith(original_input_fasta_p, ".gz")){ # delete decompressed input files
file.remove(input_fasta_p)
}
fastainfo_df$new_file[which(fastainfo_df$fasta==input_fasta)] <- output_fasta
fastainfo_df$read_count[which(fastainfo_df$fasta==input_fasta)] <- n
}# all files
fastainfo_df <- fastainfo_df %>%
select(tag_fw,primer_fw,tag_rv,primer_rv,sample,sample_type,habitat,replicate, fasta=new_file, read_count)
new_fastainfo <- paste(outdir, "fastainfo.csv", sep="")
write.table(fastainfo_df, file = new_fastainfo,  row.names = F, sep=sep)
}
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
#'
#' @param fastainfo_df data frame with a 'fasta' column containing input file names; files can be compressed in gz and zip format
#' @param n integer; the number of randomly selected sequences
#' @param fasta_dir directory that contains the input fasta files
#' @param outdir directory for the output files
#' @param vsearch_path path to vsearch
#' @param randseed positive integer; seed for random sampling; 0 by default means to use a pseudo-random seed, a given non-zero seed produce always the same result
#' @param compress [T/F]; If TRUE, output files are compressed in the same format as the input. Otherwise the output is uncompressed;
#' @export
#'
RandomSeq <- function(fastainfo_df, fasta_dir="", outdir="", vsearch_path="", n, randseed=0, compress=F){
# quite fast for uncompressed and gz files
fasta_dir<- check_dir(fasta_dir)
vsearch_path<- check_dir(vsearch_path)
outdir<- check_dir(outdir)
fastainfo_df$new_file <- NA
fastainfo_df$read_count <- NA
unique_fasta <- unique(fastainfo_df$fasta)
for(i in 1:length(unique_fasta)){ # go through all fasta files
input_fasta <- unique_fasta[i]
# adjust output filename in function of the compression
output_fasta <- input_fasta
if(compress && !endsWith(output_fasta, ".gz")){
output_fasta <- paste(output_fasta, ".gz", sep="")
}
if(!compress && endsWith(output_fasta, ".gz")){
output_fasta <- sub(".gz$", "", output_fasta)
}
if(endsWith(input_fasta, ".zip")){
stop("Zip files are not supported")
}
original_input_fasta_p <- paste(fasta_dir, input_fasta, sep="")
input_fasta_p <- paste(fasta_dir, input_fasta, sep="") # name can change if file de/recompressed
if(!is_linux() && endsWith(original_input_fasta_p, ".gz")){ #Decompress input files, since they are cannot be treated directly by vsearch on the OS
input_fasta_p <- decompress_file(input_fasta_p, remove_input=F)
}
output_fasta_p <- paste(outdir, input_fasta, sep="")
seq_n <- count_seq(file=input_fasta_p)
if(n > seq_n ){ # not enough seq
file.copy(original_input_fasta_p, output_fasta_p)
msg <- paste("WARNING:", input_fasta_p,"has",seq_n,"sequences, which is lower than", n,". The file is copied to the",outdir,"directory without subsampling", sep=" ")
print(msg)
# the original file has been decompressed  => remove the decompressed file
if(input_fasta_p != original_input_fasta_p){
file.remove(input_fasta_p)
}
# the outfile is not yet compressed
if(compress && !endsWith(output_fasta_p, ".gz")){
output_fasta_p <- compress_file(filename=output_fasta_p, remove_input=T)
}
fastainfo_df$new_file[which(fastainfo_df$fasta==input_fasta)] <- output_fasta
fastainfo_df$read_count[which(fastainfo_df$fasta==input_fasta)] <- seq_n
next()
}
# enough seq => resample
options(scipen=100) # do not transform large numbers to scentific forms, since it would lead to an error in vsearch
output_fasta_p <- gsub(".gz", "", output_fasta_p) # vsearch makes decompressed files
vsearch_cmd <- paste(vsearch_path, "vsearch --fastx_subsample ", input_fasta_p, " --fastaout ", output_fasta_p, " --sample_size ", n, " --randseed ", randseed, sep="")
print(vsearch_cmd)
system(vsearch_cmd)
options(scipen=0)
if(compress){ # compress the output file
output_fasta_p <- compress_file(filename=output_fasta_p, remove_input=T)
}
if(!is_linux() && endsWith(original_input_fasta_p, ".gz")){ # delete decompressed input files
file.remove(input_fasta_p)
}
fastainfo_df$new_file[which(fastainfo_df$fasta==input_fasta)] <- output_fasta
fastainfo_df$read_count[which(fastainfo_df$fasta==input_fasta)] <- n
}# all files
fastainfo_df <- fastainfo_df %>%
select(tag_fw,primer_fw,tag_rv,primer_rv,sample,sample_type,habitat,replicate, fasta=new_file, read_count)
new_fastainfo <- paste(outdir, "fastainfo.csv", sep="")
write.table(fastainfo_df, file = new_fastainfo,  row.names = F, sep=sep)
}
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
#'
#' @param fastainfo_df data frame with a 'fasta' column containing input file names; files can be compressed in gz and zip format
#' @param n integer; the number of randomly selected sequences
#' @param fasta_dir directory that contains the input fasta files
#' @param outdir directory for the output files
#' @param vsearch_path path to vsearch
#' @param randseed positive integer; seed for random sampling; 0 by default means to use a pseudo-random seed, a given non-zero seed produce always the same result
#' @param compress [T/F]; If TRUE, output files are compressed in the same format as the input. Otherwise the output is uncompressed;
#' @export
#'
RandomSeq <- function(fastainfo_df, fasta_dir="", outdir="", vsearch_path="", n, randseed=0, compress=F){
# quite fast for uncompressed and gz files
fasta_dir<- check_dir(fasta_dir)
vsearch_path<- check_dir(vsearch_path)
outdir<- check_dir(outdir)
fastainfo_df$new_file <- NA
fastainfo_df$read_count <- NA
unique_fasta <- unique(fastainfo_df$fasta)
for(i in 1:length(unique_fasta)){ # go through all fasta files
input_fasta <- unique_fasta[i]
# adjust output filename in function of the compression
output_fasta <- input_fasta
if(compress && !endsWith(output_fasta, ".gz")){
output_fasta <- paste(output_fasta, ".gz", sep="")
}
if(!compress && endsWith(output_fasta, ".gz")){
output_fasta <- sub(".gz$", "", output_fasta)
}
if(endsWith(input_fasta, ".zip")){
stop("Zip files are not supported")
}
original_input_fasta_p <- paste(fasta_dir, input_fasta, sep="")
input_fasta_p <- paste(fasta_dir, input_fasta, sep="") # name can change if file de/recompressed
if(!is_linux() && endsWith(original_input_fasta_p, ".gz")){ #Decompress input files, since they are cannot be treated directly by vsearch on the OS
input_fasta_p <- decompress_file(input_fasta_p, remove_input=F)
}
output_fasta_p <- paste(outdir, input_fasta, sep="")
seq_n <- count_seq(file=input_fasta_p)
if(n > seq_n ){ # not enough seq
file.copy(original_input_fasta_p, output_fasta_p)
msg <- paste("WARNING:", input_fasta_p,"has",seq_n,"sequences, which is lower than", n,". The file is copied to the",outdir,"directory without subsampling", sep=" ")
print(msg)
# the original file has been decompressed  => remove the decompressed file
if(input_fasta_p != original_input_fasta_p){
file.remove(input_fasta_p)
}
# the outfile is not yet compressed
if(compress && !endsWith(output_fasta_p, ".gz")){
output_fasta_p <- compress_file(filename=output_fasta_p, remove_input=T)
}
fastainfo_df$new_file[which(fastainfo_df$fasta==input_fasta)] <- output_fasta
fastainfo_df$read_count[which(fastainfo_df$fasta==input_fasta)] <- seq_n
next()
}
# enough seq => resample
options(scipen=100) # do not transform large numbers to scentific forms, since it would lead to an error in vsearch
output_fasta_p <- gsub(".gz", "", output_fasta_p) # vsearch makes decompressed files
vsearch_cmd <- paste(vsearch_path, "vsearch --fastx_subsample ", input_fasta_p, " --fastaout ", output_fasta_p, " --sample_size ", n, " --randseed ", randseed, sep="")
print(vsearch_cmd)
system(vsearch_cmd)
options(scipen=0)
if(compress){ # compress the output file
output_fasta_p <- compress_file(filename=output_fasta_p, remove_input=T)
}
if(!is_linux() && endsWith(original_input_fasta_p, ".gz")){ # delete decompressed input files
file.remove(input_fasta_p)
}
fastainfo_df$new_file[which(fastainfo_df$fasta==input_fasta)] <- output_fasta
fastainfo_df$read_count[which(fastainfo_df$fasta==input_fasta)] <- n
}# all files
fastainfo_df <- fastainfo_df %>%
select(tag_fw,primer_fw,tag_rv,primer_rv,sample,sample_type,habitat,replicate, fasta=new_file, read_count)
new_fastainfo <- paste(outdir, "fastainfo.csv", sep="")
write.table(fastainfo_df, file = new_fastainfo,  row.names = F, sep=sep)
}
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
computer <- "Windows" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
swarm_path <- ""
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_updated_2024_02_19_after_swarm.csv"
#  fastqdir <- "/home/meglecz/vtamR_large_files/fastq/"
#  fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#  outdir <- "/home/meglecz/vtamR_large_files/out/"
#  mock_composition <- "/home/meglecz/vtamR_large_files/user_input/mock_composition_mfzr.csv"
#  asv_list <- "/home/meglecz/vtamR_large_files/user_input/asv_list.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
swarm_path <- ""
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
#    fastqdir <- "~/vtamR_large_data"
#    fastqinfo <- "~/vtamR_large_data/metadata/fastqinfo_Sea18_IIICBR_vtamR.csv"
#    outdir <- "/home/emese/vtamR_out_large_dataset/"
#    mock_composition <- "~/vtamR_large_data/metadata/mock_composition_Sea18_IIICBR_vtamR.csv"
#    asv_list <- "~/vtamR_large_data/metadata/asv_list.csv"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/swarm-3.1.4-win-x86_64/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
num_threads=4
compress = F
}
sep=","
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files
# create the output directory and check the the slash at the end
outdir <- check_dir(dir=outdir)
fastqdir <- check_dir(dir=fastqdir)
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
###
### Merge
###
fastq_ascii <- 33
fastq_maxdiffs <- 10
fastq_maxee <- 1
fastq_minlen <- 50
fastq_maxlen <- 500
fastq_minmergelen <- 50
fastq_maxmergelen <-500
fastq_maxns <- 0
fastq_truncqual <- 10
fastq_minovlen <- 50
fastq_allowmergestagger <- F
merged_dir <- paste(outdir, "merged/", sep="")
compress = T
# read fastqinfo
fastqinfo_df <- read.csv(fastqinfo, header=T, sep=sep)
###
### RandomSeq
###
randomseq_dir = paste(outdir, "random_seq/", sep="")
fastainfo <- paste(merged_dir, "fastainfo.csv", sep="")
fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
compress = T
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
compress = F
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
compress
computer <- "Windows" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
swarm_path <- ""
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_updated_2024_02_19_after_swarm.csv"
#  fastqdir <- "/home/meglecz/vtamR_large_files/fastq/"
#  fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#  outdir <- "/home/meglecz/vtamR_large_files/out/"
#  mock_composition <- "/home/meglecz/vtamR_large_files/user_input/mock_composition_mfzr.csv"
#  asv_list <- "/home/meglecz/vtamR_large_files/user_input/asv_list.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
swarm_path <- ""
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
#    fastqdir <- "~/vtamR_large_data"
#    fastqinfo <- "~/vtamR_large_data/metadata/fastqinfo_Sea18_IIICBR_vtamR.csv"
#    outdir <- "/home/emese/vtamR_out_large_dataset/"
#    mock_composition <- "~/vtamR_large_data/metadata/mock_composition_Sea18_IIICBR_vtamR.csv"
#    asv_list <- "~/vtamR_large_data/metadata/asv_list.csv"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/swarm-3.1.4-win-x86_64/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_zfzr.csv"
asv_list <- "vtamR_test/data/asv_list_zfzr.csv"
num_threads=4
compress = F
}
sep=","
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files
# create the output directory and check the the slash at the end
outdir <- check_dir(dir=outdir)
fastqdir <- check_dir(dir=fastqdir)
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
###
### Merge
###
fastq_ascii <- 33
fastq_maxdiffs <- 10
fastq_maxee <- 1
fastq_minlen <- 50
fastq_maxlen <- 500
fastq_minmergelen <- 50
fastq_maxmergelen <-500
fastq_maxns <- 0
fastq_truncqual <- 10
fastq_minovlen <- 50
fastq_allowmergestagger <- F
merged_dir <- paste(outdir, "merged/", sep="")
compress = T
# read fastqinfo
fastqinfo_df <- read.csv(fastqinfo, header=T, sep=sep)
###
### RandomSeq
###
randomseq_dir = paste(outdir, "random_seq/", sep="")
fastainfo <- paste(merged_dir, "fastainfo.csv", sep="")
fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
compress = F
RandomSeq_windows(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, n=10000, randseed=0, compress=compress)
