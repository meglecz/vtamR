library("devtools")
library("roxygen2")
library("seqinr")
library("dplyr")
library("tidyr")
library("utils") # to handle zipped files
computer <- "Bombyx" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
setwd("~/vtamR")
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "local/fastq/"
num_threads=8
} else if (computer == "Endoume"){
setwd("~/vtamR")
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path="" # deactivate conda
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
fastqdir <- "local/fastq/"
num_threads=8
}else if (computer == "Windows"){
setwd("C:/Users/emese/vtamR/")
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
num_threads=4
}
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
fastqinfo <- "local/user_input/fastqinfo_mfzr_eu.csv"
mock_composition <- "local/user_input/mock_composition_mfzr_eu.csv"
sep=";"
# create the output directory and check the the slash at the end
outdir <- check_dir(dir="local/out")
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
test_merge_and_sortreads(vsearch_path=vsearch_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
test_merge_and_sortreads(vsearch_path=vsearch_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
test_merge_and_sortreads(vsearch_path=vsearch_path)
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
###
# run Sortreads using the same parameters as vtam
fastainfo_df <- read.csv("vtamR_test/test/merged/fastainfo.csv", header=T, sep=sep)
sorted_dir <- "vtamR_test/test/sorted/"
check_reverse <- T
tag_to_end <- F
primer_to_end <-F
cutadapt_error_rate <- 0.1 # -e in cutadapt
cutadapt_minimum_length <- 50 # -m in cutadapt
cutadapt_maximum_length <- 500 # -M in cutadapt
compress <- "0"
fileinfo_df <- SortReads(fastainfo_df=fastainfo_df, fastadir=outdir, outdir=sorted_dir, cutadapt_path=cutadapt_path, vsearch_path=vsearch_path, check_reverse=check_reverse, tag_to_end=tag_to_end, primer_to_end=primer_to_end, cutadapt_error_rate=cutadapt_error_rate, cutadapt_minimum_length=cutadapt_minimum_length, cutadapt_maximum_length=cutadapt_maximum_length, sep=sep, compress=compress)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
###
# Test merge
###
test_merge_and_sortreads(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path)
test_filters <- function(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, sep=sep){
sorted_dir <- "/home/meglecz/vtamR/vtamR_test/test/sorted/"
fileinfo_df <- read.csv("/home/meglecz/vtamR/vtamR_test/test/sorted/fileinfo.csv", sep=sep)
read_count_df <- read_fastas_from_fileinfo(fileinfo_df, dir=sorted_dir, write_csv=F, outdir=outdir, sep=sep)
global_read_count_cutoff = 2
read_count_df <- LFN_global_read_count(read_count_df, global_read_count_cutoff, write_csv=T, outdir=outdir, sep=sep)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, write_csv=T, outdir = outdir, sep=sep)
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
read_count_df_lnf_sample_replicate <- LFN_sample_replicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, write_csv=T, outdir = outdir, sep=sep)
# LFN_sample_variant (by line)
lnf_variant_cutoff = 0.001
by_replicate = TRUE
read_count_df_lnf_variant <- LFN_variant(read_count_df, cutoff=lnf_variant_cutoff, by_replicate, write_csv=T, outdir = outdir, sep=sep)
param_values <- paste(lnf_variant_cutoff, by_replicate, sep=";")
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
read_count_df <- pool_LFN(read_count_df_lfn_read_count, read_count_df_lnf_variant, read_count_df_lnf_sample_replicate, write_csv=T, outdir = outdir, sep=sep)
stat_df <- get_stat(read_count_df, stat_df, stage="FilterLFN")
# delete temporary data frames
read_count_df_lfn_read_count <- NULL
read_count_df_lnf_variant <- NULL
read_count_df_lnf_sample_replicate <- NULL
### keep repeatable occurrences
min_replicate_number <- 2
read_count_df <- FilterMinReplicateNumber(read_count_df, min_replicate_number, write_csv=T, outdir = outdir, sep=sep)
### FilerPCRerror
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 1
read_count_df <- FilterPCRerror(read_count_df, write_csv=T, outdir=outdir, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
### FilterChimera
vsearch_path = ""
abskew=16
by_sample = T
sample_prop = 1
read_count_df <- FilterChimera(read_count_df, write_csv=T, outdir=outdir, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
### FilerRenkonen
renkonen_distance_quantile = 0.9
read_count_df <- FilerRenkonen(read_count_df, write_csv=T, outdir=outdir, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
### FilerIndel
read_count_df <- FilterIndel(read_count_df, write_csv=T, outdir=outdir, sep=sep)
### FilerCodonStop
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, write_csv=T, outdir=outdir, genetic_code=genetic_code, sep=sep)
### PoolReplicates
digits = 0
read_count_samples_df <- PoolReplicates(read_count_df, digits=digits, write_csv=T, outdir=outdir, sep=sep)
}
test_filters(vsearch_path=vsearch_path, cutadapt_path=cutadapt_path, sep=sep)
sorted_dir <- "/home/meglecz/vtamR/vtamR_test/test/sorted/"
fileinfo_df <- read.csv("/home/meglecz/vtamR/vtamR_test/test/sorted/fileinfo.csv", sep=sep)
View(fileinfo_df)
read_count_df <- read_fastas_from_fileinfo(fileinfo_df, dir=sorted_dir, write_csv=F, outdir=outdir, sep=sep)
global_read_count_cutoff = 2
outdir <- "/home/meglecz/vtamR/vtamR_test/test/filter/"
read_count_df <- LFN_global_read_count(read_count_df, global_read_count_cutoff, write_csv=F, outdir=outdir, sep=sep)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, write_csv=T, outdir = outdir, sep=sep)
View(read_count_df)
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, write_csv=F, outdir = outdir, sep=sep)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, write_csv=F, outdir = outdir, sep=sep)
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
read_count_df_lnf_sample_replicate <- LFN_sample_replicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, write_csv=F, outdir = outdir, sep=sep)
# LFN_sample_variant (by line)
lnf_variant_cutoff = 0.001
by_replicate = TRUE
read_count_df_lnf_variant <- LFN_variant(read_count_df, cutoff=lnf_variant_cutoff, by_replicate, write_csv=F, outdir = outdir, sep=sep)
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
read_count_df <- pool_LFN(read_count_df_lfn_read_count, read_count_df_lnf_variant, read_count_df_lnf_sample_replicate, write_csv=F, outdir = outdir, sep=sep)
# delete temporary data frames
read_count_df_lfn_read_count <- NULL
read_count_df_lnf_variant <- NULL
read_count_df_lnf_sample_replicate <- NULL
### keep repeatable occurrences
min_replicate_number <- 2
read_count_df <- FilterMinReplicateNumber(read_count_df, min_replicate_number, write_csv=F, outdir = outdir, sep=sep)
### FilerPCRerror
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 1
read_count_df <- FilterPCRerror(read_count_df, write_csv=F, outdir=outdir, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
### FilterChimera
vsearch_path = ""
abskew=16
by_sample = T
sample_prop = 1
read_count_df <- FilterChimera(read_count_df, write_csv=F, outdir=outdir, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
### FilerRenkonen
renkonen_distance_quantile = 0.9
read_count_df <- FilerRenkonen(read_count_df, write_csv=F, outdir=outdir, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
### FilerIndel
read_count_df <- FilterIndel(read_count_df, write_csv=F, outdir=outdir, sep=sep)
### FilerCodonStop
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, write_csv=F, outdir=outdir, genetic_code=genetic_code, sep=sep)
### PoolReplicates
digits = 0
read_count_samples_df <- PoolReplicates(read_count_df, digits=digits, write_csv=T, outdir=outdir, sep=sep)
# wide format (ASV table), samples are in columns, ASVs in lines
outfile=paste(outdir, "Final_asvtable.csv", sep="")
write_asvtable(read_count_samples_df, outfile=outfile, fileinfo=fileinfo, add_empty_samples=T, add_sums_by_sample=F, add_sums_by_asv=F, add_expected_asv=F, mock_composition=mock_composition, sep=sep)
write_asvtable(read_count_samples_df, outfile=outfile, add_empty_samples=T, add_sums_by_sample=F, add_sums_by_asv=F, add_expected_asv=F,  sep=sep)
View(read_count_samples_df)
# wide format (ASV table), samples are in columns, ASVs in lines
outfile=paste(outdir, "Final_asvtable.csv", sep="")
write_asvtable(read_count_samples_df, outfile=outfile, add_empty_samples=T, add_sums_by_sample=F, add_sums_by_asv=F, add_expected_asv=F,  sep=sep)
write_asvtable(read_count_samples_df, outfile=outfile, add_empty_samples=F, add_sums_by_sample=F, add_sums_by_asv=F, add_expected_asv=F,  sep=sep)
read_count_samples_df <- read_count_samples_df %>%
select(asv, plate1.MFZR.14ben01, plate1.MFZR.14ben02, plate1.MFZR.tnegtag, plate1.MFZR.tpos1)
sorted_dir <- "/home/meglecz/vtamR/vtamR_test/test/sorted/"
fileinfo_df <- read.csv("/home/meglecz/vtamR/vtamR_test/test/sorted/fileinfo.csv", sep=sep)
outdir <- "/home/meglecz/vtamR/vtamR_test/test/filter/"
read_count_df <- read_fastas_from_fileinfo(fileinfo_df, dir=sorted_dir, write_csv=F, outdir=outdir, sep=sep)
global_read_count_cutoff = 2
read_count_df <- LFN_global_read_count(read_count_df, global_read_count_cutoff, write_csv=F, outdir=outdir, sep=sep)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, write_csv=F, outdir = outdir, sep=sep)
### LFN_filters
# LFN_read_count
lfn_read_count_cutoff <- 10
read_count_df_lfn_read_count <- LFN_read_count(read_count_df, cutoff=lfn_read_count_cutoff, write_csv=F, outdir = outdir, sep=sep)
# LFN_sample_replicate (by column)
lfn_sample_replicate_cutoff <- 0.001
read_count_df_lnf_sample_replicate <- LFN_sample_replicate(read_count_df, cutoff=lfn_sample_replicate_cutoff, write_csv=F, outdir = outdir, sep=sep)
# LFN_sample_variant (by line)
lnf_variant_cutoff = 0.001
by_replicate = TRUE
read_count_df_lnf_variant <- LFN_variant(read_count_df, cutoff=lnf_variant_cutoff, by_replicate, write_csv=F, outdir = outdir, sep=sep)
# pool the results of the different filterLFN to one data frame; keep only occurrences that passed all filters
read_count_df <- pool_LFN(read_count_df_lfn_read_count, read_count_df_lnf_variant, read_count_df_lnf_sample_replicate, write_csv=F, outdir = outdir, sep=sep)
# delete temporary data frames
read_count_df_lfn_read_count <- NULL
read_count_df_lnf_variant <- NULL
read_count_df_lnf_sample_replicate <- NULL
View(read_count_df)
wide_read_count_df <- as.data.frame(pivot_wider(read_count_df, names_from = c(plate, marker, sample, replicate), values_from = read_count, values_fill=0, names_sep = ".", names_sort=T))
View(wide_read_count_df)
### keep repeatable occurrences
min_replicate_number <- 2
read_count_df <- FilterMinReplicateNumber(read_count_df, min_replicate_number, write_csv=F, outdir = outdir, sep=sep)
### FilerPCRerror
pcr_error_var_prop <- 0.1
max_mismatch <- 1
by_sample <- T
sample_prop <- 1
read_count_df <- FilterPCRerror(read_count_df, write_csv=F, outdir=outdir, vsearch_path=vsearch_path, pcr_error_var_prop=pcr_error_var_prop, max_mismatch=max_mismatch, by_sample=by_sample, sample_prop=sample_prop, sep=sep)
### FilterChimera
abskew=16
by_sample = T
sample_prop = 1
read_count_df <- FilterChimera(read_count_df, write_csv=F, outdir=outdir, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
### FilerRenkonen
renkonen_distance_quantile = 0.9
read_count_df <- FilerRenkonen(read_count_df, write_csv=F, outdir=outdir, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
### FilerIndel
read_count_df <- FilterIndel(read_count_df, write_csv=F, outdir=outdir, sep=sep)
### FilterChimera
abskew=2
by_sample = T
sample_prop = 1
read_count_df <- FilterChimera(read_count_df, write_csv=F, outdir=outdir, vsearch_path=vsearch_path, by_sample=by_sample, sample_prop=sample_prop, abskew=abskew, sep=sep)
### FilerRenkonen
renkonen_distance_quantile = 0.9
read_count_df <- FilerRenkonen(read_count_df, write_csv=F, outdir=outdir, renkonen_distance_quantile=renkonen_distance_quantile, sep=sep)
### FilerIndel
read_count_df <- FilterIndel(read_count_df, write_csv=F, outdir=outdir, sep=sep)
### FilerCodonStop
genetic_code = 5
read_count_df <- FilterCodonStop(read_count_df, write_csv=F, outdir=outdir, genetic_code=genetic_code, sep=sep)
wide_read_count_df <- as.data.frame(pivot_wider(read_count_df, names_from = c(plate, marker, sample, replicate), values_from = read_count, values_fill=0, names_sep = ".", names_sort=T))
View(wide_read_count_df)
write.csv(file="/home/meglecz/vtamR/vtamR_test/test/user_input/test_file.csv", wide_read_count_df)
