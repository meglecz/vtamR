digits = 0
read_count_samples_df <- PoolReplicates(read_count_df, digits=digits, write_csv=T, outdir=outdir, sep=sep)
# taxassign
asv_tax <- TaxAssign(df=read_count_samples_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outdir=outdir, num_threads=num_threads)
# write the list of ASV and their taxonomic assignment
write.csv(asv_tax, file = paste(outdir, "taxa.csv", sep=""), row.names = F)
fileinfo <- "/home/meglecz/vtamR/vtamR_test/out_mfzr/sorted/fileinfo.csv"
write_asvtable(read_count_samples_df, outfile="asvtable_swarm_mfzr.csv", fileinfo=fileinfo, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
write_asvtable(read_count_samples_df, outfile="vtamR_test/out_mfzr/asvtable_swarm_mfzr.csv", fileinfo=fileinfo, asv_tax=asv_tax, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
computer <- "Bombyx" # Bombyx/Endoume/Windows
if(computer == "Bombyx"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/meglecz/miniconda3/envs/vtam_2/bin/"
vsearch_path = ""
blast_path="~/ncbi-blast-2.11.0+/bin/" # bombyx
swarm_path <- ""
db_path="~/mkLTG/COInr_for_vtam_2022_05_06_dbV5/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_zfzr_gz.csv"
outdir <- "vtamR_test/out_zfzr/"
mock_composition <- "vtamR_test/data/mock_composition_mfzr_eu.csv"
#fastqdir <- "/home/meglecz/vtamR_large_files/fastq/"
#fastqinfo <- "/home/meglecz/vtamR_large_files/user_input/fastqinfo_mfzr.csv"
#outdir <- "/home/meglecz/vtamR_large_files/out/"
#mock_composition <- "local/user_input/mock_composition_mfzr_prerun.csv"
num_threads=8
compress = T
} else if (computer == "Endoume"){
vtam_dir <- "~/vtamR"
cutadapt_path="/home/emese/miniconda3/bin/"
vsearch_path = "/home/emese/miniconda3/bin/"
blast_path= "" # deactivate conda
swarm_path <- ""
db_path= "/home/emese/mkCOInr/COInr/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "local/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=8
compress = T
}else if (computer == "Windows"){
vtam_dir <- "C:/Users/emese/vtamR/"
cutadapt_path="C:/Users/Public/"
vsearch_path = "C:/Users/Public/vsearch-2.23.0-win-x86_64/bin/"
blast_path="C:/Users/Public/blast-2.14.1+/bin/"
swarm_path <- "C:/swarm-3.1.4-win-x86_64/bin/"
db_path="C:/Users/Public/COInr_for_vtam_2023_05_03_dbV5/"
#  fastqdir <- "C:/Users/emese/vtamR_private/fastq/"
fastqdir <- "vtamR_test/data/"
fastqinfo <- "vtamR_test/data/fastqinfo_mfzr_gz.csv"
outdir <- "vtamR_test/out/"
num_threads=4
compress = F
}
sep=";"
setwd(vtam_dir)
taxonomy=paste(db_path, "COInr_for_vtam_taxonomy.tsv", sep="")
blast_db=paste(db_path, "COInr_for_vtam", sep="")
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c("species","species","species","genus","family","family"),
ltgres=c("species","species","species","species", "genus","genus")
)
ltg_params_df = data.frame( pid=c(100,97,95,90,85,80),
pcov=c(70,70,70,70,70,70),
phit=c(70,70,70,70,70,70),
taxn=c(1,1,2,3,4,4),
seqn=c(1,1,2,3,4,4),
refres=c(8,8,8,7,6,6),
ltgres=c(8,8,8,8,7,7)
)
#setwd("D:/vtamR")
# load local packages
load_all(".")
roxygenise() # Builds the help files
usethis::use_roxygen_md() # rebuild the help files ?
# create the output directory and check the the slash at the end
outdir <- check_dir(dir=outdir)
# Measure runtime using system.time()
start_time <- Sys.time()  # Record the start time
# define stat data frame that will be completed with counts after each step
stat_df <- data.frame(parameters=character(),
asv_count=integer(),
read_count=integer(),
sample_count=integer(),
sample_replicate_count=integer())
###
### Merge
###
fastq_ascii <- 33
fastq_maxdiffs <- 10
fastq_maxee <- 1
fastq_minlen <- 50
fastq_maxlen <- 500
fastq_minmergelen <- 50
fastq_maxmergelen <-500
fastq_maxns <- 0
fastq_truncqual <- 10
fastq_minovlen <- 50
fastq_allowmergestagger <- F
merged_dir <- paste(outdir, "merged/", sep="")
compress = T
# read fastqinfo
fastqinfo_df <- read.csv(fastqinfo, header=T, sep=sep)
fastainfo_df <- Merge(fastqinfo_df=fastqinfo_df, fastqdir=fastqdir, vsearch_path=vsearch_path, outdir=merged_dir, fastq_ascii=fastq_ascii, fastq_maxdiffs=fastq_maxdiffs, fastq_maxee=fastq_maxee, fastq_minlen=fastq_minlen, fastq_maxlen=fastq_maxlen, fastq_minmergelen=fastq_minmergelen, fastq_maxmergelen=fastq_maxmergelen, fastq_maxns=fastq_maxns, fastq_truncqual=fastq_truncqual, fastq_minovlen=fastq_minovlen, fastq_allowmergestagger=fastq_allowmergestagger, sep=sep, compress=compress)
###
### RandomSeq
###
randomseq_dir = paste(outdir, "random_seq/", sep="")
#fastainfo <- paste(merged_dir, "fastainfo_gz.csv", sep="")
#fastainfo_df <- read.csv(file=fastainfo, header=T, sep=sep)
compress = T
RandomSeq(fastainfo_df, fasta_dir=merged_dir, outdir=randomseq_dir, vsearch_path=vsearch_path, n=10000, randseed=0, compress=compress)
###
### SortReads
###
sorted_dir <- paste(outdir, "sorted", sep="")
check_reverse <- T
tag_to_end <- F
primer_to_end <-F
cutadapt_error_rate <- 0.1 # -e in cutadapt
cutadapt_minimum_length <- 50 # -m in cutadapt
cutadapt_maximum_length <- 500 # -M in cutadapt
compress <- F
fileinfo_df <- SortReads(fastainfo_df=fastainfo_df, fastadir=merged_dir, outdir=sorted_dir, cutadapt_path=cutadapt_path, vsearch_path=vsearch_path, check_reverse=check_reverse, tag_to_end=tag_to_end, primer_to_end=primer_to_end, cutadapt_error_rate=cutadapt_error_rate, cutadapt_minimum_length=cutadapt_minimum_length, cutadapt_maximum_length=cutadapt_maximum_length, sep=sep, compress=compress)
###
### Read input fasta files, dereplicate reads to ASV, and count the number of reads of each ASV in each plate-marker-sample-replicate
###
read_count_df <- read_fastas_from_fileinfo(fileinfo_df, dir=sorted_dir, write_csv=T, outdir=outdir, sep=sep)
# make stat counts
stat_df <- get_stat(read_count_df, stat_df, stage="Input", params=NA)
read_count_df_backup <- read_count_df
swarm_d <- 1
fastidious <- TRUE
by_sample <- TRUE
read_count_df <- swarm(read_count_df, outdir=outdir, swarm_path=swarm_path, num_threads=num_threads, swarm_d=swarm_d, fastidious=fastidious, write_csv=T, sep=sep, by_sample=by_sample)
params <- paste(swarm_d, fastidious, by_sample, se=";")
stat_df <- get_stat(read_count_df, stat_df, stage="swarm", params=params)
digits = 0
read_count_samples_df <- PoolReplicates(read_count_df, digits=digits, write_csv=T, outdir=outdir, sep=sep)
# taxassign
asv_tax <- TaxAssign(df=read_count_samples_df, ltg_params_df=ltg_params_df, taxonomy=taxonomy, blast_db=blast_db, blast_path=blast_path, outdir=outdir, num_threads=num_threads)
# write the list of ASV and their taxonomic assignment
write.csv(asv_tax, file = paste(outdir, "taxa.csv", sep=""), row.names = F)
fileinfo <- "/home/meglecz/vtamR/vtamR_test/out_zfzr/sorted/fileinfo.csv"
write_asvtable(read_count_samples_df, outfile="vtamR_test/out_zfzr/asvtable_swarm_zfzr.csv", fileinfo=fileinfo, asv_tax=asv_tax, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
mock_composition <- "vtamR_test/data/mock_composition_zfzr_eu.csv"
write_asvtable(read_count_samples_df, outfile="vtamR_test/out_zfzr/asvtable_swarm_zfzr.csv", fileinfo=fileinfo, asv_tax=asv_tax, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
fileinfo <- "/home/meglecz/vtamR/vtamR_test/out_zfzr/sorted/fileinfo.csv"
write_asvtable(read_count_samples_df, outfile="vtamR_test/out_zfzr/asvtable_swarm_zfzr.csv", fileinfo=fileinfo, asv_tax=asv_tax, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
mock_composition
write_asvtable(read_count_samples_df, outfile="vtamR_test/out_zfzr/asvtable_swarm_zfzr.csv", fileinfo=fileinfo, asv_tax=asv_tax, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
write_asvtable(read_count_samples_df, outfile="vtamR_test/out_zfzr/asvtable_swarm_zfzr.csv", fileinfo=fileinfo, asv_tax=asv_tax, add_empty_samples=T, add_sums_by_sample=T, add_sums_by_asv=T, add_expected_asv=T, mock_composition=mock_composition, sep=sep)
files <- data.frame(file=c("vtamR_test/out_zfzr/asvtable_swarm_mfzr.csv", "vtamR_test/out_zfzr/asvtable_swarm_zfzr.csv"),
marker=c("MFZR", "ZFZR"))
View(files)
marker_list <- uniqe(files$marker)
marker_list <- unique(files$marker)
marker_list
df <- data.frame()
View(df)
for(file in file_list){
tmp <- read.csv(file, sep=sep)
rbind(df, tmp)
}
file_list <- unique(files$file)
df <- data.frame()
for(file in file_list){
tmp <- read.csv(file, sep=sep)
rbind(df, tmp)
}
getwd()
files <- data.frame(file=c("vtamR_test/out_mfzr/PoolReplicates.csv", "vtamR_test/out_zfzr/PoolReplicates.csv"),
marker=c("MFZR", "ZFZR"))
file_list <- unique(files$file)
df <- data.frame()
for(file in file_list){
tmp <- read.csv(file, sep=sep)
rbind(df, tmp)
}
View(tmp)
file_list
for(file in file_list){
print(file)
tmp <- read.csv(file, sep=sep)
rbind(df, tmp)
}
for(file in file_list){
print(file)
tmp <- read.csv(file, sep=sep)
rbind(df, tmp)
}
df <- data.frame(
asv=character(),
sample=character(),
mean_read_count=real()
)
df <- data.frame()
for(file in file_list){
print(file)
tmp <- read.csv(file, sep=sep) %>%
select(asv, sample, mean_read_count)
rbind(df, tmp)
}
file_list <- unique(files$file)
df <- data.frame()
df <- data.frame("asv" = list(), "sample" = list(), "mean_read_count" = list())
for(file in file_list){
print(file)
tmp <- read.csv(file, sep=sep) %>%
select(asv, sample, mean_read_count)
rbind(df, tmp)
}
df <- data.frame("asv" = list(), "sample" = list(), "mean_read_count" = list())
file_list <- unique(files$file)
df <- data.frame(
asv=character(),
sample=character(),
mean_read_count=integer()
)
for(file in file_list){
print(file)
tmp <- read.csv(file, sep=sep) %>%
select(asv, sample, mean_read_count)
rbind(df, tmp)
}
View(df)
View(tmp)
df <- data.frame("asv" = list(), "sample" = list(), "mean_read_count" = list())
for(file in file_list){
print(file)
tmp <- read.csv(file, sep=sep) %>%
select(asv, sample, mean_read_count)
df <- rbind(df, tmp)
}
View(df)
summary(df)
df <- data.frame("asv" = list(), "sample" = list(), "mean_read_count" = list(), "marker"== list())
i=1
file <- files[i, "file"]
marker <- files[i, "marker"]
print(file)
tmp <- read.csv(file, sep=sep) %>%
select(asv, sample, mean_read_count)
tmp$marker <- rep(marker, nrow(tmp))
df <- rbind(df, tmp)
df <- data.frame("asv" = list(), "sample" = list(), "mean_read_count" = list(), "marker"== list())
for(i in 1:nrow(files)){
file <- files[i, "file"]
marker <- files[i, "marker"]
print(file)
tmp <- read.csv(file, sep=sep) %>%
select(asv, sample, mean_read_count)
tmp$marker <- rep(marker, nrow(tmp))
df <- rbind(df, tmp)
}
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
View(asvs)
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count)) %>%
arrange(desc(rc))
asvs$id <- ronames(asvs)
asvs$id <- rownames(asvs)
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "_", asvs$rc, "\n", asvs$asv, sep="" ), fasta)
vsearch_cmd <- paste(vsearch_path, " vsearch --cluster_size ", fasta, " --alnout alnout.txt --blast6out blast6out.tsv --centroids centroids.txt --clusters clusters.txt msaout msaout.txt --id 1", sep="")
print(vsearch_cmd)
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_size ", fasta, " --alnout alnout.txt --blast6out blast6out.tsv --centroids centroids.txt --clusters clusters.txt msaout msaout.txt --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_size ", fasta, " --alnout alnout.txt --blast6out blast6out.tsv --centroids centroids.txt --clusters clusters.txt --msaout msaout.txt --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_size ", fasta, " --otutabout vtamR_test/out_mfzrotutabout.txt --blast6out vtamR_test/blast6out.tsv --centroids vtamR_test/centroids.txt --clusters vtamR_test/clusters --msaout vtamR_test/msaout.txt --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_size ", fasta, " --consout vtamR_test/consout.txt --blast6out vtamR_test/blast6out.tsv --centroids vtamR_test/centroids.txt --clusters vtamR_test/clusters --msaout vtamR_test/msaout.txt --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length))
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length))
# make a fasta file with decreasing abundances
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "\n", asvs$asv, sep="" ), fasta)
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length), desc(rc))
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length), desc(rc))
# make a fasta file with decreasing abundances
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "_", asvs$rc, "\n", asvs$asv, sep="" ), fasta)
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_smallmem ", fasta, " --consout vtamR_test/consout.txt --blast6out vtamR_test/blast6out.tsv --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
# make a fasta file with decreasing abundances
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "\n", asvs$asv, sep="" ), fasta)
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_smallmem ", fasta, " --consout vtamR_test/consout.txt --blast6out vtamR_test/blast6out.tsv --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
cons <- read.table("vtamR_test/consout.txt")
View(cons)
cons <- read.table("vtamR_test/consout.txt") %>%
filter(gsub(">centroid=", "", V1))
colnames(cons) <- c("heading")
cons <- cons %>%
filter(gsub(">centroid=", "", V1))
cons <- cons %>%
filter(grepl(">centroid=", heading))
gsub(">centroid=", "", cons$heading)
cons$heading <- gsub(">centroid=", "", cons$heading)
cons$heading <- gsub(";.+", "", cons$heading)
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length), desc(rc))
# make a fasta file with decreasing abundances
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "\n", asvs$asv, sep="" ), fasta)
centroids <- paste(outdir, "consout.txt", sep="")
blastout <- paste(outdir, "blastout.tsv", sep="")
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_smallmem ", fasta, " --consout centroids --blast6out blastout --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
cons <- read.table(centroids)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$centroid <- gsub(";.+", "", cons$centroid)
centroids <- paste(outdir, "consout.txt", sep="")
blastout <- paste(outdir, "blastout.tsv", sep="")
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_smallmem ", fasta, " --consout ",centroids," --blast6out ", blastout," --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
cons <- read.table(centroids)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$centroid <- gsub(";.+", "", cons$centroid)
# add centroids to the blastout
blastout <- read.table(blastout_file)
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length), desc(rc))
# make a fasta file with decreasing abundances
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "\n", asvs$asv, sep="" ), fasta)
centroids_file <- paste(outdir, "consout.txt", sep="")
blastout_file <- paste(outdir, "blastout.tsv", sep="")
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_smallmem ", fasta, " --consout ",centroids_file," --blast6out ", blastout_file," --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
# read the ids of centoids
cons <- read.table(centroids_file)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$centroid <- gsub(";.+", "", cons$centroid)
# add centroids to the blastout
blastout <- read.table(blastout_file)
View(blastout)
# add centroids to the blastout
blastout <- read.table(blastout_file, col.names=c("query", "subject"))
# add centroids to the blastout
blastout <- read.table(blastout_file) %>%
select(1,2)
colnames(blastout) <- c("query", "subject")
left_join(blastout, cons, by= c("query" = "centroid"))
blastout$query <- as.character(blastout$query)
left_join(blastout, cons, by= c("query" = "centroid"))
blastout <- left_join(blastout, cons, by= c("query" = "centroid"))
asvs <- df %>%
group_by(asv) %>%
summarize("rc" = sum(mean_read_count))
asvs$id <- rownames(asvs)
asvs$length <- nchar(asvs$asv)
asvs <- asvs %>%
arrange(desc(length), desc(rc))
# make a fasta file with decreasing abundances
fasta <- paste(outdir, "vsearch_input.fasta", sep="")
writeLines(paste(">", asvs$id, "\n", asvs$asv, sep="" ), fasta)
centroids_file <- paste(outdir, "consout.txt", sep="")
blastout_file <- paste(outdir, "blastout.tsv", sep="")
vsearch_cmd <- paste(vsearch_path, "vsearch --cluster_smallmem ", fasta, " --consout ",centroids_file," --blast6out ", blastout_file," --id 1", sep="")
print(vsearch_cmd)
system(vsearch_cmd)
# read the ids of centoids
cons <- read.table(centroids_file)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$centroid <- gsub(";.+", "", cons$centroid)
# add centroids to the blastout
blastout <- read.table(blastout_file) %>%
select(1,2)
colnames(blastout) <- c("query", "subject")
blastout$query <- as.character(blastout$query)
cons <- left_join(cons, blastout, by= c("centroid"="query"))
blastout <- read.table(blastout_file) %>%
select(1,2)
colnames(blastout) <- c("query", "subject")
blastout$query <- as.character(blastout$query)
blastout$subject <- as.character(blastout$subject)
cons <- left_join(cons, blastout, by= c("centroid"="subject"))
# read the ids of centoids
cons <- read.table(centroids_file)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$nbseq <-  gsub(".+;seq=", "", cons$centroid)
# read the ids of centoids
cons <- read.table(centroids_file)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$nbseq <-  cons$centroid
cons$centroid <- gsub(";.+", "", cons$centroid)
cons$nbseq <-  gsub(".+;seq=", "", cons$nbseq)
cons$nbseq <-  gsub(".+;seqs=", "", cons$nbseq)
# read the ids of centoids
cons <- read.table(centroids_file)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$nbseq <-   gsub(".+;seqs=", "", cons$centroid)
cons$centroid <- gsub(";.+", "", cons$centroid)
# add centroids to the blastout
blastout <- read.table(blastout_file) %>%
select(1,2)
colnames(blastout) <- c("query", "subject")
blastout$query <- as.character(blastout$query)
blastout$subject <- as.character(blastout$subject)
cons <- left_join(cons, blastout, by= c("centroid"="subject"))
dim(cons)
cons$query <- which(is.na(cons$query), cons$centroid)
cons <- cons %>%
mutate(query = ifelse(is.na(query), centroid, query))
dim(cons)
added_lines <- cons %>%
filter(nbseq>1) %>%
mutate(query=centroid) %>%
rbind(cons)
dim(cons)
added_lines <- cons %>%
filter(nbseq>1) %>%
mutate(query=centroid) %>%
cons<- rbind(cons, added_lines)
cons <- read.table(centroids_file)
colnames(cons) <- c("centroid")
cons <- cons %>%
filter(grepl(">centroid=", centroid))
cons$centroid <- gsub(">centroid=", "", cons$centroid)
cons$nbseq <-   gsub(".+;seqs=", "", cons$centroid)
cons$centroid <- gsub(";.+", "", cons$centroid)
# add to centroid the seqid that are in the same cluster
blastout <- read.table(blastout_file) %>%
select(1,2)
colnames(blastout) <- c("query", "subject")
blastout$query <- as.character(blastout$query)
blastout$subject <- as.character(blastout$subject)
cons <- left_join(cons, blastout, by= c("centroid"="subject"))
cons <- cons %>%
mutate(query = ifelse(is.na(query), centroid, query))
added_lines <- cons %>%
filter(nbseq>1) %>%
mutate(query=centroid)
dim(cons)
cons<- rbind(cons, added_lines)
dim(cons)
View(stat_df)
