# Ideas for vtamR



### get %id or swarm R for clustering
## density plot % identity of ASVs within and between clusters
# %id among all sequences (use vsearch all_againts_all, ignore asv too different)
# clustering with variying d
# for each d, density plot

## classify clustrers
# clustering with variying d
# taxassign all ASV
# for each d classify each clusters at each taxlevel
#  - close => All same taxon within cluster, all ASV of th taxon is in the same cluster
#  - open => All same taxon within cluster, same taxon is fauld in other cluster as well
#  - hybrid-compatible => different taxa within cluster but they are all compatible => taxa and NA
#  - hybrid-noncompatible => different taxa within cluster and it is not due to NA


## replace test_filters by an R script to run with demo files
## Joining with `by = join_by(asv, sample, replicate, read_count)`Joining with `by = join_by(asv, sample, replicate, read_count)`[1] "PoolFilters: PASS"
Avoid warning when running test_filters

## make useable examples

## integrate MakeKnownOccurrences to OptimizeLFNreadCountLFNvariant ?? Raise warning if FN. , add option to use custom knownOccurrences files
=> modify vignette accordingly


## Merge:  arguments 'show.output.on.console', 'minimized' and 'invisible' are for Windows only

## WriteASVtable => include replicates if necessary

## work on compression-decompression

## Generally, better gestion of the wd
	setwd for test. do not change de directory in test_Merge 
	Check slash at the end of dir names in all cases. Check is missing in MakeKnownOccurrences
	
## Protect against failure in system calls:
	status <- system(cmd)
	if (status != 0) {
	  stop("vsearch failed. Check if the command and paths are correct.")
	}
	learn more about system and system2
	
	
## Remote BLAST in mkLTG
	filter out incorrect names on the fly



# DONE 

## 2025/05/06
- Add sep to params in FilterIndel, FilterCodonStop => DONE
- Add Cluster_size function and its internal functions to cluster ASVs to mOTU with fixed limit => DONE
- Allow df or CSV for mock_composition in WriteASVtable => DONE
- Complete lineage of Taxassign if missing taxlevels above resolution => Done, argument fill_lineage is added => DONE

## 2025/06/17

- Print message for CheckFileinfo => DONE; 
	- quiet option is added (default FALSE)
	- if quiet == TRUE, there are no 'OK' messages (just to say that a test is done and everythin is OK). It is to use when cjhecking file info from within another function.
	- if quiet == FALSE, there are 'OK' messages. It is usefull when run directly by the users.

## 2025/06/19

- Better gestion of path => DONE
	- Use file.path() instead of paste() for file paths
	- check_dir => creates dir, but do not add /
	- use tempdir() to get temp_dir names => if multiple runs of the same command, make new subdir for each run and delete it afterwards
		Fonctions modified:
		-SortReads
		-SortReads_no_reverse
		-run_swarm
		-PoolDatasets
		-flagPCRerror_vsearch
		-flagChimera
		-TaxAssign
		-OptimizePCRerror
		-Cluster_size
		
## 2025/06/24 tested on windows

- check_path (experimental in Installation_vtamR.Rmd) !!!!!!!! CHECK
- use path+executable names for binaries => DONE

## 2025/06/24

- add citation,  => DONE
- complete DESCRIPTION => DONE
- run and correct small bugs with devtools::check() and results <- rcmdcheck::rcmdcheck() => DONE
- \donttest{} examples => DONE

## 2025/06/24 check()

- add citation => DONE
- use devtools::check() and correct formatting => DONE
- make conda env with third party programs => DONE

## 2025/06/25 install()

- check on windows => DONE
- make readme, doc, vignette structure => DONE
- correct license, DESCRIPTION => DONE

## 2025/06/27 vignette install()

- develop vignettes, but EVAL=FALSE => see if it can be built if COInr is installed locally. Alternativelly, use df with taxassign results => DONE
DONE, test database is used for taxassing 

## 2025/07/03 demo files

- tutorial-vtamr-pipeline vignette adapted and uses only data comming from the package => DONE
- adapt make-mock-composition-file using the test database => DONE
 
## 2025/07/07 from-fastq-to-df
Make a separate vignette, with different strategies of merge-Sortreads => DONE

 
## 2025/07/28

- tutorial-vtamr-pipeline => Adjust graphic size in html => DONE
- revise installation => DONE

## 2025/07/29 vignettes revised

- print stat df, which is too large print => knitr::kable(stat_df, format = "markdown") => DONE
- revise tutorial-vtamr-pipeline, from-fastq-to-df and make-mock-compositxc vhion-file vignettes => DONE
- PCR error => make explicit that is these parametre values are just for demo (tuto)  => DONE
- install
- build
- add tarball to github
- push

## 2025/07/30 web_doc

- Transfer install to README; install with pak and either vignettes from tarball or use webpage
- change outdir to relative path in linux
- change link to glossary in readme
- web_doc copy vignettes Rmd, change TOC, knit for making html on website
- Rempace mkCOInr paper by VTAM paper

## 2025/07/31

- CheckFileinfo completed => DONE
	check if sample names are all alphanumerical
	if only IUPAC char in tag, primer and asv
	rad_count numerical

- clustering
	Add cluster vsearch at the end of the tuto => DONE
	Clustering by fixed threshold => DONE 
	Make swarm and ClusterSize adapted to both read_count_df and read_count_sample_df => DONE
	Both swarm and ClusterSize can be run by sample or all toghether => DONE
	
## 2025/08/01
	
- Add swarm as an alternative for clustering at the end => DONE
- MakeKnownOccurrences => add PoolReplicates, if necessary => DONE
- Revise output file names and folders in tutrial => DONE
- modify check_dir to create a directory or is does not exist and if it file, create a directory of the file => DONE
- SortReads read_counts column filled

## 2025/08/04


- check input df or csv in every function and same for output
	Merge return csv or df => DONE
	add_ids : it is a filename. Maybe it could be also a data frame.=> DONE
	Mock_composition : it is a filename. Maybe it could be also a data frame. => DONE
	UpdateASVlist => DONE

- Check obligatory heading in doc for known_occurrences (tuto) => DONE

- Check the use of asv_id in taxassign. asv_id are obligatory and they are used in BLAST

## 2025/08/05

- num_threads is 0 by default. If num_threads set => use value, => DONE
	If not, do not add num_thread to the command => 
	this will make blats on 1 strand swarm ???, vsearch and cutadpat on max

- iclude cutadapt_minimum_length and cutadapt_maximum_length to SortReads in tutorial  => DONE

- PoolFilters  Joining with `by = join_by(asv_id, sample, replicate, read_count, asv)` => suppressMessages() => DONE




